{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2449\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1981\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1049\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0833\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0345\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0812\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0537\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1217\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0415\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0914\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0642\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0970\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0879\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0599\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0347\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0644\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0081\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0849\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0313\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0723\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0464\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0207\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0172\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0259\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0066\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0204\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0236\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0298\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0102\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0231\n",
      "elapsed:  90.66921186447144\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0627901715071251\n",
      "tensor(1.)\n",
      "torch.Size([100, 784])\n",
      "sample size: torch.Size([100, 784])\n",
      "relu Size: torch.Size([800, 100])\n",
      "Average Active Neurons = 246.48\n",
      "sparsity 0.6919\n",
      "Accuracy of the network on the 10000 test images: 98.1 %\n"
     ]
    }
   ],
   "source": [
    "#test maxpooling after relu: how does it perform?  It seems it performs well. 98.25 is observed. \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 800\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "num_workers=0\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=True,\n",
    "                                   download=False, transform=transform)\n",
    "test_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=False,\n",
    "                                  download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers, shuffle = True)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        \n",
    "        #98.25, 98\n",
    "#         self.maxpool=nn.MaxPool1d(2, 1)\n",
    "#         self.fc2 = nn.Linear(799, num_classes)   \n",
    "        \n",
    "        #98.09\n",
    "#         self.maxpool=nn.MaxPool1d(2, 2)\n",
    "#         self.fc2 = nn.Linear(400, num_classes)   \n",
    "        \n",
    "        #97.79\n",
    "#         self.maxpool=nn.MaxPool1d(3, 2)\n",
    "#         self.fc2 = nn.Linear(399, num_classes) \n",
    "\n",
    "        #98.1\n",
    "        self.maxpool=nn.MaxPool1d(4, 4)\n",
    "        self.fc2 = nn.Linear(200, num_classes) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.fc1(out)\n",
    "        out_relu = self.relu(out)        \n",
    "        out = self.maxpool(out_relu.unsqueeze(1)).squeeze(1)\n",
    "        out = self.fc2(out)\n",
    "        return out, out_relu   \n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "#test\n",
    "# A = torch.randn(2,4)#2 is data size, 4 is feature input size\n",
    "# print(A)\n",
    "# A = A.unsqueeze_(0)\n",
    "# print(A.shape)\n",
    "# print(model.maxpool(A))\n",
    "\n",
    "#visualzing graphs\n",
    "# writer=SummaryWriter('runs/experiment_1')\n",
    "# dataiter=iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(images.shape)\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# #writer.add_image('images', grid, 0)\n",
    "\n",
    "# #images = images.reshape(-1, 28*28).to(device)\n",
    "# dummy_input = torch.zeros(1, 28*28),\n",
    "# writer.add_graph(model, dummy_input)\n",
    "# writer.close()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, _  = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "\n",
    "print('elapsed: ', time.time()-start)\n",
    "plt.plot(losses, '-b+')\n",
    "plt.show()\n",
    "print(np.mean(losses))\n",
    "\n",
    "#check dead neurons\n",
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.reshape(-1, 28*28).to(device)\n",
    "print(torch.max(images[0]))#pixels are normalized\n",
    "\n",
    "print(images.shape)\n",
    "A1 = images[:100]\n",
    "print(\"sample size:\", A1.shape)\n",
    "output, output_relu = model(A1)\n",
    "\n",
    "output_relu = output_relu.T.detach()\n",
    "print(\"relu Size:\", output_relu.shape)# interesting, data size is in second dimension. \n",
    "# plt.plot(output_relu.numpy(), '-b+')\n",
    "# plt.show()\n",
    "print('Average Active Neurons =', np.count_nonzero(output_relu)/A1.shape[0])\n",
    "print('sparsity', 1- np.count_nonzero(output_relu)/ (output_relu.shape[0] * output_relu.shape[1]))\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "labels_wrong = []\n",
    "pred_wrong = []\n",
    "img_wrong = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, labels in test_loader:\n",
    "#         print(img.shape)\n",
    "        images = img.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        wrong_preds = (predicted != labels).numpy()\n",
    "        wrong_index = []\n",
    "        for (i, wrong) in enumerate(wrong_preds):\n",
    "            if wrong:\n",
    "                wrong_index.append(i) \n",
    "        if len(wrong_index) > 0:\n",
    "            img_reshaped = img[wrong_index].numpy()[:,0,:,:]\n",
    "            for img_w in range(img_reshaped.shape[0]):\n",
    "                img_wrong.append(img_reshaped[img_w])\n",
    "            labels_wrong  += (labels[wrong_index].numpy().tolist())\n",
    "            pred_wrong += (predicted[wrong_index].numpy().tolist())\n",
    "#     print(img_wrong)\n",
    "#     print('img_wrong.shape', img_wrong[0].shape)\n",
    "#     print('lables_wrong =', labels_wrong)\n",
    "#     print('predictions wrong are:', pred_wrong)\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "#show wrong images:\n",
    "# print(len(img_wrong), ', ', len(labels_wrong), ', ', len(pred_wrong))\n",
    "# for i in range(len(img_wrong)):\n",
    "#     plt.imshow(img_wrong[i])\n",
    "#     print('labels_wrong[i]:', labels_wrong[i])\n",
    "#     print('pred_wrong[i]', pred_wrong[i])\n",
    "#     plt.pause(1)\n",
    "\n",
    "# Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Active Neurons = 37.462\n",
      "layer 1:\n",
      "[Parameter containing:\n",
      "tensor([[ 0.0130, -0.0188, -0.0024,  ..., -0.0205, -0.0091, -0.0043],\n",
      "        [ 0.0033, -0.0016,  0.0280,  ..., -0.0147, -0.0031,  0.0006],\n",
      "        [ 0.0079,  0.0102,  0.0261,  ..., -0.0042, -0.0020, -0.0068],\n",
      "        ...,\n",
      "        [-0.0171,  0.0092,  0.0084,  ...,  0.0206,  0.0248,  0.0227],\n",
      "        [ 0.0295,  0.0247,  0.0058,  ..., -0.0149,  0.0173, -0.0035],\n",
      "        [ 0.0348,  0.0101,  0.0070,  ...,  0.0008,  0.0263, -0.0051]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 4.5606e-02, -8.7214e-03,  6.5915e-02, -2.7034e-02,  4.6711e-02,\n",
      "         3.8341e-02,  1.8096e-02,  1.7200e-02,  3.2345e-02, -6.4435e-02,\n",
      "        -1.9535e-02,  3.6509e-02,  1.8641e-02,  2.1812e-02, -6.9894e-02,\n",
      "        -3.1382e-02, -4.6306e-02,  1.7369e-01, -1.7433e-02,  3.5536e-02,\n",
      "        -1.5135e-02, -4.6255e-02, -1.6067e-02,  3.7119e-02, -5.2715e-03,\n",
      "         1.9340e-02, -5.4811e-02, -3.1189e-02,  1.0628e-01, -5.9413e-02,\n",
      "         3.2564e-02, -5.6688e-03,  5.3045e-02,  9.0088e-03, -7.0852e-03,\n",
      "        -7.8958e-04,  1.2716e-03, -5.2556e-03, -7.4646e-03, -1.6943e-02,\n",
      "         6.9714e-02,  1.4044e-02, -6.0080e-02,  2.0178e-02, -2.2394e-02,\n",
      "         1.7625e-02, -4.6556e-02,  1.7880e-02,  1.1039e-02,  2.0918e-02,\n",
      "        -2.5954e-02, -7.9955e-03, -8.4244e-02,  2.9089e-02,  6.5932e-02,\n",
      "         5.5733e-02, -6.4621e-02,  7.3909e-02, -3.1039e-02, -3.1484e-02,\n",
      "        -8.1424e-03, -4.3214e-02, -7.0470e-03,  2.3588e-02,  3.4756e-02,\n",
      "         4.2056e-04,  8.3391e-02,  1.3967e-02,  7.1620e-02, -3.3731e-02,\n",
      "        -3.8899e-02, -1.4415e-03,  2.4781e-02,  7.5222e-02, -1.3309e-02,\n",
      "         2.3759e-02,  2.4987e-02,  3.7883e-02,  7.0833e-02,  6.4792e-02,\n",
      "         4.2034e-02,  2.9059e-02,  5.2292e-02,  7.7332e-02, -6.3001e-03,\n",
      "        -1.7858e-02, -1.2082e-02,  5.4612e-02, -3.9634e-02, -5.9022e-02,\n",
      "        -2.7410e-02, -9.6043e-03, -3.7962e-02,  9.2622e-03,  3.4352e-02,\n",
      "        -7.1566e-04,  3.5429e-02,  6.7719e-02,  1.2770e-02,  2.0616e-02,\n",
      "         5.4464e-02,  1.2919e-01, -1.2640e-02,  6.5282e-03,  4.3497e-02,\n",
      "         5.1912e-02,  1.6006e-02,  4.9353e-02,  1.1153e-02, -3.4716e-02,\n",
      "        -1.0647e-02,  7.6781e-03,  6.8343e-02, -3.0489e-02,  1.1503e-02,\n",
      "        -2.4442e-02,  2.4542e-02, -1.6423e-03, -1.2030e-02, -8.7269e-03,\n",
      "         8.9073e-03,  1.0987e-02, -5.1227e-02,  2.8335e-02,  1.0400e-02,\n",
      "        -2.9407e-02, -5.7380e-02,  1.6942e-02,  3.2469e-02,  2.6801e-02,\n",
      "        -3.8349e-02,  7.1896e-02, -1.2283e-03, -1.8689e-02, -1.9519e-02,\n",
      "         6.6803e-02, -5.7335e-02,  3.5204e-02,  7.2868e-04,  2.7767e-02,\n",
      "         3.1765e-02, -1.5523e-02, -4.2467e-02, -2.1506e-02,  4.4315e-02,\n",
      "         2.4518e-02,  1.3377e-03,  4.4967e-02, -3.4568e-02, -3.8758e-02,\n",
      "         4.2841e-02, -3.8058e-02,  1.0172e-02,  2.1137e-02, -4.4640e-03,\n",
      "         3.2503e-02,  1.0521e-02, -1.3269e-02, -1.4388e-02, -3.5900e-02,\n",
      "         4.0401e-02, -3.3647e-02,  4.6135e-02, -1.2176e-03,  6.5839e-03,\n",
      "         4.2197e-02,  3.4256e-02,  1.1286e-01,  6.9851e-02, -9.5754e-03,\n",
      "        -3.4230e-02,  5.3626e-02,  7.5959e-02,  4.8225e-02,  9.9445e-02,\n",
      "         8.0105e-03,  6.6573e-03, -1.0963e-02, -2.2752e-03,  4.7086e-02,\n",
      "         1.3182e-02,  6.3068e-02, -1.7314e-02, -3.5524e-02, -8.9618e-02,\n",
      "        -6.4506e-02, -2.1929e-02, -2.6995e-02, -5.2766e-05,  4.4487e-02,\n",
      "         8.8833e-03,  6.9965e-02,  3.2153e-03, -2.0945e-02, -9.5496e-03,\n",
      "        -1.8518e-03,  1.0156e-01, -3.9285e-02,  1.6619e-02, -8.6584e-02,\n",
      "        -4.8955e-02,  5.5615e-02,  3.2547e-02, -4.8525e-02, -2.6588e-02,\n",
      "        -2.6077e-02,  5.6051e-03,  1.6212e-02, -2.1915e-02,  1.9396e-03,\n",
      "         2.0467e-02, -2.9198e-02,  8.8569e-02, -1.6358e-04,  2.2769e-03,\n",
      "        -4.4054e-02,  5.1759e-02,  9.0957e-02,  2.3596e-02, -4.3008e-03,\n",
      "        -3.2703e-02, -5.7063e-03,  3.1302e-02, -6.8360e-02,  3.1619e-02,\n",
      "         9.3879e-02,  2.8976e-02,  2.7682e-03,  5.3162e-02,  6.0703e-03,\n",
      "         4.5386e-02,  9.5195e-03, -5.3459e-02,  7.1768e-02, -2.8763e-02,\n",
      "         7.1860e-03, -5.4795e-02, -8.6467e-02, -1.9357e-04,  3.5820e-02,\n",
      "         8.3895e-02, -1.3192e-02,  4.5015e-02,  1.0655e-02, -2.8369e-02,\n",
      "         6.0337e-02, -1.9112e-02, -3.1754e-02, -2.9697e-02,  2.6265e-02,\n",
      "        -5.8131e-03,  7.1158e-03, -1.9470e-02,  3.9133e-02,  2.9827e-02,\n",
      "         9.8042e-03, -2.4295e-02,  7.0669e-02, -1.6955e-02,  1.3191e-02,\n",
      "         6.6144e-02,  1.3811e-03,  2.1016e-02, -5.5616e-02,  3.5124e-02,\n",
      "         7.7630e-02,  1.3055e-01,  3.0906e-03, -2.6614e-02, -5.3930e-03,\n",
      "         1.7808e-02,  1.2209e-01,  2.8028e-02,  3.9663e-02, -1.8637e-02,\n",
      "         2.0539e-02, -2.3793e-03,  4.5559e-02, -3.2710e-02,  6.0751e-02,\n",
      "         7.6649e-03,  9.7795e-03, -2.7452e-02,  2.5875e-02,  3.0546e-02,\n",
      "        -4.7749e-02,  1.2965e-01, -3.1853e-02, -1.3850e-02, -1.1841e-02,\n",
      "         2.9938e-02,  1.0982e-02, -5.5761e-02,  2.4140e-02,  6.6126e-02,\n",
      "        -2.8823e-02, -2.0759e-02, -2.7462e-02,  1.2926e-02,  4.4329e-02,\n",
      "        -6.1533e-02,  1.5342e-02, -9.2040e-03, -3.3715e-03,  4.2618e-02,\n",
      "         7.5908e-02, -1.7509e-02,  5.1014e-04,  1.5183e-02,  1.0436e-02,\n",
      "         4.1071e-02,  5.3767e-03,  2.3180e-02,  3.8262e-02, -2.9802e-02,\n",
      "         1.5526e-02,  4.2126e-02,  7.4912e-02,  1.5979e-02,  7.9306e-02,\n",
      "        -2.9945e-02, -3.7039e-02,  3.2260e-02,  1.2299e-02,  5.6954e-02,\n",
      "        -6.4975e-02,  8.9161e-02,  2.6947e-02,  4.4164e-02,  1.2197e-02,\n",
      "         1.4109e-02, -2.8430e-03, -2.0751e-02, -5.5645e-02,  1.9415e-03,\n",
      "         5.4756e-02, -1.9423e-02, -3.1441e-03, -2.3445e-03,  2.3694e-02,\n",
      "         2.5649e-02, -2.5775e-02,  5.4326e-02, -2.0529e-02,  8.6809e-03,\n",
      "         1.1820e-01, -6.5228e-02,  6.6104e-02,  4.8296e-02, -7.5664e-02,\n",
      "         6.6189e-02,  1.3977e-02,  4.8213e-02, -2.6428e-02, -6.2585e-02,\n",
      "        -2.1348e-02, -4.6005e-02, -5.5252e-02,  7.4930e-02,  7.1291e-02,\n",
      "         1.9897e-02,  2.0231e-02,  4.0584e-02, -1.2299e-02,  8.1589e-02,\n",
      "         1.5981e-02,  1.7969e-02, -8.0408e-03, -2.8926e-03,  3.6392e-03,\n",
      "         5.2355e-02,  4.2852e-02, -6.6345e-02,  4.3546e-02,  1.6746e-02,\n",
      "         2.4928e-03,  7.5091e-02,  5.2476e-02,  2.2694e-02,  6.3391e-02,\n",
      "         1.5392e-02,  7.1546e-02, -2.5151e-02, -1.5101e-02,  4.6466e-02,\n",
      "        -2.2622e-02,  2.4787e-02, -1.8238e-03,  3.7768e-03, -4.2260e-02,\n",
      "         3.0793e-02,  1.1419e-01,  2.0803e-03,  1.8669e-02,  4.9435e-02,\n",
      "         2.2347e-02, -5.6051e-02, -2.6536e-02,  1.0197e-01,  3.4533e-02,\n",
      "        -3.1389e-02, -7.6450e-02,  2.6703e-03, -5.6084e-02, -4.4734e-03,\n",
      "        -3.5498e-02,  7.5444e-02,  3.4847e-02,  1.9533e-02,  9.6805e-03,\n",
      "         9.0696e-02, -3.4148e-02, -1.1498e-02,  2.5503e-02,  2.4095e-04,\n",
      "         5.3353e-02, -2.8139e-02,  5.4743e-02,  1.6494e-02,  9.2381e-02,\n",
      "        -8.4002e-02,  2.6053e-02, -1.4349e-02, -1.5922e-02,  1.3694e-02,\n",
      "         2.1730e-03,  7.7297e-02, -4.9760e-02,  8.2016e-03, -4.7823e-02,\n",
      "         3.2043e-02,  6.8214e-03,  8.6583e-02, -3.8421e-02,  2.4499e-02,\n",
      "        -3.2574e-03,  3.8076e-03, -4.3707e-02, -1.0516e-02, -1.9288e-02,\n",
      "         1.7301e-02,  4.7159e-02, -6.0897e-04,  9.6922e-03, -1.4971e-02,\n",
      "         9.3970e-02, -7.6754e-03,  2.2072e-02, -2.2016e-02, -1.2804e-02,\n",
      "        -1.5691e-02,  7.4864e-02, -7.4242e-02, -5.9246e-02, -1.0907e-02,\n",
      "         4.3244e-02,  2.7741e-02,  3.3394e-02, -8.9748e-02, -8.7571e-02,\n",
      "         3.5101e-02, -8.4394e-02, -5.0802e-02, -3.6395e-02,  6.6747e-02,\n",
      "         3.6684e-02, -1.7591e-02, -2.9969e-02, -1.2622e-02, -3.5432e-02,\n",
      "        -3.3104e-02,  8.8118e-02,  8.0812e-02, -3.4994e-02,  3.1103e-02,\n",
      "        -4.7850e-02, -9.4733e-03,  3.7925e-02,  1.7221e-02,  3.7125e-02,\n",
      "        -1.2528e-02,  1.5633e-02, -2.6299e-02,  5.7935e-02, -5.4553e-03,\n",
      "        -1.0559e-02,  7.9758e-02,  3.0871e-02, -3.5175e-02,  4.8422e-03,\n",
      "         4.4088e-02, -2.0866e-02,  4.3121e-02, -4.2904e-02, -5.0624e-02,\n",
      "         1.9874e-02, -2.1427e-02,  7.3820e-02,  1.8757e-02, -5.2640e-04,\n",
      "        -3.6559e-02,  3.1213e-02, -2.1253e-02, -1.5326e-02, -3.1099e-02,\n",
      "        -3.6040e-02,  1.5640e-01, -5.4918e-02,  9.3257e-02,  1.2407e-03,\n",
      "        -2.3634e-03, -1.9375e-03,  2.2169e-02,  3.7682e-02,  7.1853e-03,\n",
      "        -8.7566e-02,  2.0677e-03, -5.4930e-02, -4.3668e-04, -1.5679e-02,\n",
      "         3.2709e-02,  4.0179e-02,  2.8571e-02, -3.1078e-02, -1.9311e-02,\n",
      "        -6.0696e-02,  4.6141e-02, -5.3671e-02,  4.6193e-02,  6.9413e-02,\n",
      "        -2.9670e-02,  2.8304e-02, -4.6503e-02,  4.2162e-02,  2.5417e-02,\n",
      "         5.4381e-02,  1.2850e-02, -4.4397e-02, -2.7332e-02,  2.7781e-02,\n",
      "         4.9837e-02, -1.5481e-03,  1.7046e-02, -2.8270e-02, -2.0159e-02,\n",
      "         1.2873e-02,  1.1300e-02,  3.4400e-02,  3.6118e-02,  3.6674e-03,\n",
      "        -7.8840e-02,  2.1909e-02,  3.0429e-02, -1.1189e-02,  2.7330e-02,\n",
      "         4.4138e-02,  1.4178e-02,  1.3413e-02,  4.4438e-02,  1.9030e-02,\n",
      "        -2.2350e-02,  4.8119e-02,  9.8161e-02,  2.1822e-02,  6.9992e-02,\n",
      "        -2.6718e-02, -2.0800e-02, -3.9225e-02, -1.9216e-02,  4.8080e-02,\n",
      "        -3.0780e-02,  1.0501e-01, -9.4270e-03,  2.4556e-02, -3.0274e-02,\n",
      "         3.2946e-02,  1.1534e-02,  5.5002e-02, -4.3895e-03, -4.8096e-02,\n",
      "        -2.0898e-02, -3.9661e-02, -1.4687e-02,  1.7820e-02,  3.6583e-02,\n",
      "        -4.3285e-02, -1.6193e-02, -2.0502e-02,  1.8113e-02,  2.3586e-02,\n",
      "         9.7242e-03,  6.1828e-02,  3.4645e-02, -7.3539e-04,  2.3035e-02,\n",
      "         7.2627e-02,  1.0163e-01,  2.0383e-02,  1.6001e-03,  1.7002e-03,\n",
      "         1.5504e-02, -1.5760e-02,  6.8470e-02, -5.4688e-03, -1.5710e-02,\n",
      "        -1.4646e-02,  8.4554e-02,  4.0927e-02,  6.4976e-02, -3.0051e-02,\n",
      "         6.3965e-03,  8.8718e-02,  4.1012e-02, -7.0229e-03,  8.1015e-02,\n",
      "         6.0137e-02, -6.4158e-03,  7.8168e-02,  4.1779e-02,  6.1527e-02,\n",
      "         3.6467e-02, -5.6414e-03,  3.5815e-02, -6.5663e-02,  1.2876e-02,\n",
      "         4.4593e-02,  2.9341e-03,  2.5815e-03, -7.0580e-02,  6.8308e-02,\n",
      "         6.7009e-02,  3.9558e-02, -2.2790e-02, -3.8541e-02, -3.8024e-02,\n",
      "         1.0262e-02,  5.8310e-02, -3.2640e-02,  3.9890e-02, -1.1184e-02,\n",
      "         5.7646e-02,  7.3860e-02,  7.4846e-03, -4.4581e-02,  1.4595e-02,\n",
      "        -2.2603e-02,  6.4942e-03,  1.9235e-02,  2.9192e-02, -2.3725e-02,\n",
      "        -5.2156e-02, -2.5937e-02, -3.8228e-03, -1.0126e-02,  1.0411e-01,\n",
      "         3.2508e-02,  4.7746e-03, -4.8085e-02, -1.2120e-02,  3.7607e-02,\n",
      "        -1.9376e-02,  4.6045e-02, -4.2208e-02, -3.5305e-02, -1.7497e-02,\n",
      "        -5.4140e-02,  8.7064e-03,  3.8567e-02, -2.7885e-02, -1.5630e-02,\n",
      "         6.4612e-03, -1.1284e-02,  2.0893e-03, -3.9382e-02,  2.5403e-02,\n",
      "        -5.9822e-03, -4.0724e-02,  2.7388e-02,  5.6240e-02, -3.8381e-02,\n",
      "         1.8186e-02,  2.6581e-02,  3.3658e-02,  5.7343e-02, -9.0837e-03,\n",
      "         1.0086e-02,  6.7313e-02,  8.8384e-02, -1.4206e-02,  1.2002e-02,\n",
      "         2.5178e-02,  5.1186e-02,  2.2594e-02,  1.1135e-02, -1.0082e-02,\n",
      "         3.3453e-02,  7.9607e-02,  1.8668e-02,  8.9566e-03, -3.8560e-02,\n",
      "         2.3692e-02,  4.4401e-03,  4.5828e-03,  7.6601e-02, -3.1172e-02,\n",
      "        -1.1813e-02,  1.5339e-02,  2.4051e-02,  4.4775e-02, -1.2062e-02,\n",
      "         3.8125e-02,  5.2197e-02, -3.4780e-02,  5.4848e-02,  9.8166e-02,\n",
      "        -3.8014e-02,  6.5414e-02, -1.9945e-02,  5.2936e-02, -3.4294e-02,\n",
      "        -7.4967e-02,  1.0057e-01, -2.8685e-02,  7.7017e-02, -2.7642e-02,\n",
      "         2.0899e-02,  3.7893e-02,  1.3316e-01, -4.7610e-02,  2.3597e-02,\n",
      "        -7.3428e-02, -3.3470e-02, -3.5136e-02, -1.1368e-02,  1.8964e-02,\n",
      "         1.4255e-02,  3.1018e-02,  9.2880e-02,  1.9230e-02,  1.0160e-02,\n",
      "        -5.1039e-02,  3.0448e-02, -9.2597e-03,  6.4623e-02, -7.9203e-04,\n",
      "         6.7760e-02, -6.6467e-02,  1.1413e-01,  6.3195e-03,  2.3119e-02,\n",
      "        -3.6426e-02,  6.7792e-02, -1.2845e-02,  9.4600e-02, -3.8444e-02,\n",
      "         3.9210e-03, -3.3652e-02, -7.3943e-03,  7.9893e-03,  3.9206e-02,\n",
      "         3.7044e-02,  4.7699e-02, -4.5447e-02, -3.5762e-02,  4.5820e-02,\n",
      "        -4.4242e-02,  1.7856e-02,  5.9333e-03,  3.2571e-02,  1.1847e-01,\n",
      "         5.5450e-02,  3.9421e-02,  1.8565e-02, -1.0450e-02,  2.6470e-03,\n",
      "        -2.2663e-02,  7.9599e-02,  8.5458e-03,  7.5856e-02, -1.0787e-02,\n",
      "         1.5526e-01,  8.4370e-02,  2.1325e-02,  3.7506e-02, -3.0262e-02,\n",
      "         6.5601e-02,  4.6913e-02, -2.6032e-03,  5.6119e-02, -3.1941e-02,\n",
      "         3.7456e-02,  4.1997e-03, -2.2422e-02,  4.1679e-02,  1.7250e-02,\n",
      "         3.4809e-03, -1.9777e-02, -6.7071e-02, -5.6367e-02,  4.6742e-02,\n",
      "         3.3934e-02, -3.3244e-03, -1.8634e-03, -3.0922e-02, -6.0237e-02,\n",
      "         5.2534e-04, -3.0215e-03,  3.1754e-02,  1.0277e-01, -1.4452e-03,\n",
      "         3.0849e-02,  2.7902e-02,  5.1419e-02, -1.9777e-02, -6.0762e-02,\n",
      "         1.0828e-01,  7.5379e-02, -6.6977e-03,  3.7003e-02, -2.4300e-02,\n",
      "         7.6230e-03,  2.3223e-02,  1.7524e-02, -5.3481e-02,  1.0778e-01,\n",
      "         5.5552e-02,  2.5539e-02,  2.3091e-02,  5.8898e-02,  2.2049e-02,\n",
      "         3.2623e-02,  5.8066e-02,  3.7725e-02,  2.7082e-03,  9.1510e-02,\n",
      "         4.8364e-02,  2.5851e-02,  5.0182e-02,  4.7937e-02,  4.5597e-02,\n",
      "         1.8574e-02, -3.3128e-02,  1.6021e-02,  1.8097e-02,  1.7472e-02,\n",
      "         6.0375e-02,  3.8171e-02,  8.2182e-02, -4.3193e-03,  4.6906e-02,\n",
      "         3.1633e-02, -4.2151e-02,  1.0298e-01, -2.9976e-04, -3.9288e-02,\n",
      "        -2.1534e-03,  1.7219e-02, -3.1001e-02, -7.3016e-02,  1.0867e-02,\n",
      "        -2.2472e-02, -6.8946e-02,  3.6942e-02, -3.2147e-02, -5.7080e-03,\n",
      "         3.3292e-02,  4.7618e-03,  4.2494e-02,  3.8110e-02,  3.0593e-02,\n",
      "        -2.7699e-02,  5.9018e-02,  2.6771e-02, -7.7475e-03, -8.0766e-03,\n",
      "         1.0552e-01,  3.8302e-02,  7.0903e-03, -8.4021e-02, -9.0611e-03,\n",
      "         8.9726e-02,  5.8559e-02, -2.3162e-02,  4.0500e-02, -3.4117e-02,\n",
      "        -2.6084e-02, -5.6836e-02, -1.8584e-02,  3.1332e-02,  3.6927e-02,\n",
      "        -2.0269e-03, -2.0322e-02, -7.5867e-04, -4.3515e-02,  2.0338e-02,\n",
      "        -6.0051e-02,  3.7344e-02,  4.5521e-03, -8.0622e-03,  8.1891e-02,\n",
      "        -1.9595e-02,  7.6851e-02,  5.7947e-02, -7.9975e-02, -1.4319e-02,\n",
      "         5.7971e-02,  1.1097e-02, -8.0454e-04,  2.2627e-02,  1.5486e-02,\n",
      "         2.3125e-02, -4.4649e-04,  2.2928e-02,  1.4676e-02,  3.6921e-02,\n",
      "         1.2237e-02,  3.3981e-02, -2.7515e-03, -1.9846e-02,  4.3970e-02,\n",
      "        -3.3843e-02, -4.8433e-02, -2.4778e-02, -1.7885e-02,  7.1037e-02,\n",
      "        -1.4551e-02, -3.1797e-02, -2.1153e-02,  7.8190e-03, -1.8455e-02,\n",
      "         1.1818e-03,  5.2481e-02, -2.8626e-02,  5.3633e-02, -1.6114e-02,\n",
      "         4.9092e-02,  3.8349e-02,  1.1186e-02,  8.2933e-02,  3.6620e-02,\n",
      "         2.8855e-02, -2.4173e-02, -2.0903e-02,  6.2868e-02, -4.4602e-03,\n",
      "        -1.4821e-02, -2.3536e-02,  4.3552e-02,  1.7909e-03,  2.9454e-02,\n",
      "        -5.5435e-02,  9.8082e-03, -4.3728e-02, -4.5217e-02,  3.5778e-02,\n",
      "         3.5459e-02, -1.6226e-02, -4.0777e-02,  8.0172e-02,  3.0003e-04,\n",
      "        -6.9734e-02,  9.2327e-02,  8.7332e-02, -1.5882e-02, -5.0773e-03,\n",
      "        -1.8168e-03, -5.3149e-02, -1.0497e-03,  5.5068e-03,  4.4889e-02,\n",
      "        -8.4217e-02,  2.8463e-02, -5.2897e-02,  2.5948e-02,  5.5314e-02,\n",
      "        -2.9992e-02,  2.5026e-02,  2.7934e-02,  3.3074e-02,  5.3545e-03,\n",
      "         2.7005e-03,  2.9700e-02,  1.2299e-02,  4.3918e-02,  5.8009e-03,\n",
      "         5.7190e-02,  2.5365e-02, -6.2975e-02, -6.1349e-02, -5.0910e-02,\n",
      "        -1.2906e-02,  2.8360e-02,  6.5863e-02,  3.5261e-02, -7.9101e-03,\n",
      "         7.3779e-02, -7.5745e-03, -1.9186e-02, -6.1666e-02,  3.5893e-02],\n",
      "       requires_grad=True)]\n",
      "layer 2:\n",
      "[Parameter containing:\n",
      "tensor([[-7.7061e-02, -2.3309e-01,  3.8446e-02,  ..., -1.6165e-01,\n",
      "          2.7753e-04,  6.3468e-02],\n",
      "        [-1.5375e-02, -1.2730e-02, -1.1653e-01,  ...,  2.8658e-02,\n",
      "          7.5794e-03,  1.3849e-01],\n",
      "        [-1.4670e-01,  1.0659e-01,  2.9586e-02,  ...,  1.8770e-02,\n",
      "          1.1155e-02,  1.0701e-01],\n",
      "        ...,\n",
      "        [-9.7859e-02,  5.1389e-02, -4.3696e-02,  ...,  5.4164e-02,\n",
      "         -8.3698e-03,  2.4726e-02],\n",
      "        [ 6.8566e-02,  6.6355e-02,  4.7580e-02,  ...,  1.2310e-03,\n",
      "          6.5812e-02, -2.7194e-01],\n",
      "        [-3.9793e-02, -1.6211e-01,  3.0175e-02,  ..., -7.7299e-02,\n",
      "         -3.7987e-03, -3.6984e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0479, -0.0236,  0.0244, -0.0221,  0.0430,  0.0371,  0.0069, -0.0041,\n",
      "         0.0372, -0.0036], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print('Average Active Neurons =', np.count_nonzero(output_relu)/output_relu.shape[0])\n",
    "\n",
    "print('layer 1:')\n",
    "w_fc1 = list(model.fc1.parameters())\n",
    "print(w_fc1)\n",
    "\n",
    "print('layer 2:')\n",
    "w_fc2 = list(model.fc2.parameters())\n",
    "print(w_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.1 %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#future work\n",
    "def relu_at(A, threshold):\n",
    "    return torch.max(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "def relu_min_at(A, threshold):\n",
    "    return torch.min(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "class ThresholdingNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ThresholdingNet2, self).__init__()\n",
    "        self.maxlu = ReLU_my()\n",
    "        self.minlu = ReLU_min()\n",
    "        self.fc1 = nn.Linear(input_size*2, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        out1 = self.maxlu(out)\n",
    "        out2 = self.minlu(out)\n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out  \n",
    "    \n",
    "# model = ThresholdingNet(input_size, hidden_size, num_classes).to(device)\n",
    "model = ThresholdingNet2(input_size, hidden_size, num_classes).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
