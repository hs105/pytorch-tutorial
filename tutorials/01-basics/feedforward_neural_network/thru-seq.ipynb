{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "num_workers=0\n",
    "\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=True,\n",
    "                                   download=False, transform=transform)\n",
    "test_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=False,\n",
    "                                  download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_my(A, d):\n",
    "    return torch.max(A, torch.ones_like(A) * d) - d\n",
    "\n",
    "def relu_min(A, d):\n",
    "    return torch.min(A, torch.ones_like(A) * d) - d \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU_min(nn.Module):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    References:\n",
    "        -  Related paper:\n",
    "        https://arxiv.org/pdf/1606.08415.pdf\n",
    "    Examples:\n",
    "        >>> m = silu()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "    def __init__(self, threshold):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__() # init the base class\n",
    "        self.threshold=threshold\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return relu_min(input, self.threshold)\n",
    "    \n",
    "    \n",
    "class ReLU_my(nn.Module):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    References:\n",
    "        -  Related paper:\n",
    "        https://arxiv.org/pdf/1606.08415.pdf\n",
    "    Examples:\n",
    "        >>> m = silu()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "    def __init__(self, threshold):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__() # init the base class\n",
    "        self.threshold=threshold\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return relu_my(input, self.threshold)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdingSequel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ThresholdingNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        \n",
    "        self.relu = ReLU_my(0.0)\n",
    "\n",
    "        self.relu2 = ReLU_my(0.1)\n",
    "        self.minlu = ReLU_min(0.1)\n",
    "#         self.relu2 = ReLU_my(0.3)\n",
    "#         self.minlu = ReLU_min(0.3)\n",
    "#         self.relu2 = ReLU_my(0.5)\n",
    "#         self.minlu = ReLU_min(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size * 2, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        #add thresholding to relu outputs\n",
    "        out1 = self.minlu(out)\n",
    "        out2 = self.relu2(out)\n",
    "        \n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "    \n",
    "        out = self.fc2(out)\n",
    "        return out #, out1, out2  \n",
    "\n",
    "    \n",
    "class ThresholdingNetParallel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ThresholdingNet2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        \n",
    "        self.relu = ReLU_my(0.0)\n",
    "        self.relu2 = ReLU_my(0.3)\n",
    "#         self.relu3 = ReLU_my(0.05)\n",
    "        self.relu3 = ReLU_min(0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size * 3, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out_lin = self.fc1(out)\n",
    "\n",
    "        out1 = self.relu(out_lin)\n",
    "        out2 = self.relu2(out_lin)\n",
    "        out3 = self.relu3(out_lin)\n",
    "        \n",
    "#         out = torch.cat((out1, out2), dim=1)\n",
    "        out = torch.cat((out1, out2, out3), dim=1)\n",
    "    \n",
    "        out = self.fc2(out)\n",
    "        return out #, out1, out2 \n",
    "    \n",
    "model = ThresholdingSequel(input_size, hidden_size, num_classes).to(device)\n",
    "# model = ThresholdingNetParallel(input_size, hidden_size, num_classes).to(device)\n",
    "    \n",
    "#visualzing graphs\n",
    "# writer=SummaryWriter('runs/thresholding')\n",
    "# dataiter=iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# #writer.add_image('images', grid, 0)\n",
    "\n",
    "# # images = images.reshape(-1, 28*28).to(device)\n",
    "# dummy_input = torch.zeros(1, 28*28),\n",
    "# writer.add_graph(model, dummy_input)\n",
    "# writer.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.8768\n",
      "Epoch [1/5], Step [200/600], Loss: 0.5646\n",
      "Epoch [1/5], Step [300/600], Loss: 0.3571\n",
      "Epoch [1/5], Step [400/600], Loss: 0.3768\n",
      "Epoch [1/5], Step [500/600], Loss: 0.2853\n",
      "Epoch [1/5], Step [600/600], Loss: 0.2385\n",
      "Epoch [2/5], Step [100/600], Loss: 0.2901\n",
      "Epoch [2/5], Step [200/600], Loss: 0.2238\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1904\n",
      "Epoch [2/5], Step [400/600], Loss: 0.2396\n",
      "Epoch [2/5], Step [500/600], Loss: 0.2743\n",
      "Epoch [2/5], Step [600/600], Loss: 0.2603\n",
      "Epoch [3/5], Step [100/600], Loss: 0.2057\n",
      "Epoch [3/5], Step [200/600], Loss: 0.2010\n",
      "Epoch [3/5], Step [300/600], Loss: 0.1382\n",
      "Epoch [3/5], Step [400/600], Loss: 0.2209\n",
      "Epoch [3/5], Step [500/600], Loss: 0.1081\n",
      "Epoch [3/5], Step [600/600], Loss: 0.1280\n",
      "Epoch [4/5], Step [100/600], Loss: 0.1619\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1035\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0830\n",
      "Epoch [4/5], Step [400/600], Loss: 0.1313\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0900\n",
      "Epoch [4/5], Step [600/600], Loss: 0.2329\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0465\n",
      "Epoch [5/5], Step [200/600], Loss: 0.1657\n",
      "Epoch [5/5], Step [300/600], Loss: 0.2402\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0752\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0976\n",
      "Epoch [5/5], Step [600/600], Loss: 0.1144\n",
      "elapsed:  71.44908380508423\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2240586241086324\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "\n",
    "print('elapsed: ', time.time()-start)\n",
    "plt.plot(losses, '-b+')\n",
    "plt.show()\n",
    "print(np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.42 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "labels_wrong = []\n",
    "pred_wrong = []\n",
    "img_wrong = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, labels in test_loader:\n",
    "#         print(img.shape)\n",
    "        images = img.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        wrong_preds = (predicted != labels).numpy()\n",
    "        wrong_index = []\n",
    "        for (i, wrong) in enumerate(wrong_preds):\n",
    "            if wrong:\n",
    "                wrong_index.append(i) \n",
    "        if len(wrong_index) > 0:\n",
    "            img_reshaped = img[wrong_index].numpy()[:,0,:,:]\n",
    "            for img_w in range(img_reshaped.shape[0]):\n",
    "                img_wrong.append(img_reshaped[img_w])\n",
    "            labels_wrong  += (labels[wrong_index].numpy().tolist())\n",
    "            pred_wrong += (predicted[wrong_index].numpy().tolist())\n",
    "#     print(img_wrong)\n",
    "#     print('img_wrong.shape', img_wrong[0].shape)\n",
    "#     print('lables_wrong =', labels_wrong)\n",
    "#     print('predictions wrong are:', pred_wrong)\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "#show wrong images:\n",
    "# print(len(img_wrong), ', ', len(labels_wrong), ', ', len(pred_wrong))\n",
    "# for i in range(len(img_wrong)):\n",
    "#     plt.imshow(img_wrong[i])\n",
    "#     print('labels_wrong[i]:', labels_wrong[i])\n",
    "#     print('pred_wrong[i]', pred_wrong[i])\n",
    "#     plt.pause(1)\n",
    "\n",
    "# Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('layer 1:')\n",
    "w_fc1 = list(model.fc1.parameters())\n",
    "print(w_fc1)\n",
    "\n",
    "print('layer 2:')\n",
    "w_fc2 = list(model.fc2.parameters())\n",
    "print(w_fc2)\n",
    "\n",
    "#check dead neurons\n",
    "images, labels = dataiter.next()\n",
    "images = images.reshape(-1, 28*28).to(device)\n",
    "# print(images.shape)\n",
    "A1 = images[:1]\n",
    "# print(A1.shape)\n",
    "output, output_relu, output_minlu = model(A1)\n",
    "\n",
    "output_relu = output_relu.T.detach()\n",
    "# print(output_relu.shape)\n",
    "# plt.plot(output_relu.numpy(), '-b+')\n",
    "# plt.show()\n",
    "print('np.count_nonzero(output_relu)=', np.count_nonzero(output_relu))\n",
    "# print('sparsity', 1- np.count_nonzero(output_relu)/ (output_relu.shape[0] * output_relu.shape[1]))\n",
    "\n",
    "output_minlu = output_minlu.T.detach()\n",
    "print(output_minlu.shape)\n",
    "plt.plot(output_minlu.numpy(), '-b+')\n",
    "print('np.count_nonzero(output_minlu)=', np.count_nonzero(output_minlu))\n",
    "# plt.show()\n",
    "\n",
    "#either one of minlu and relu must be activated. ignore zero features. \n",
    "assert (np.count_nonzero(output_minlu) + np.count_nonzero(output_relu) == hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#future work\n",
    "def relu_at(A, threshold):\n",
    "    return torch.max(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "def relu_min_at(A, threshold):\n",
    "    return torch.min(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "class ThresholdingNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ThresholdingNet2, self).__init__()\n",
    "        self.maxlu = ReLU_my()\n",
    "        self.minlu = ReLU_min()\n",
    "        self.fc1 = nn.Linear(input_size*2, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        out1 = self.maxlu(out)\n",
    "        out2 = self.minlu(out)\n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out  \n",
    "    \n",
    "# model = ThresholdingNet(input_size, hidden_size, num_classes).to(device)\n",
    "model = ThresholdingNet2(input_size, hidden_size, num_classes).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
