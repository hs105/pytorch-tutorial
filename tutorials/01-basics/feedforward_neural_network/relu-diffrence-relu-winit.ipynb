{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#study intialization effects on relu diff idea. Can you find a more accurate model by different initialization?\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "num_workers=0\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=True,\n",
    "                                   download=False, transform=transform)\n",
    "test_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=False,\n",
    "                                  download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 7.1186\n",
      "Epoch [1/5], Step [200/600], Loss: 4.2624\n",
      "Epoch [1/5], Step [300/600], Loss: 5.1154\n",
      "Epoch [1/5], Step [400/600], Loss: 1.5489\n",
      "Epoch [1/5], Step [500/600], Loss: 4.0116\n",
      "Epoch [1/5], Step [600/600], Loss: 2.2974\n",
      "Epoch [2/5], Step [100/600], Loss: 1.1437\n",
      "Epoch [2/5], Step [200/600], Loss: 1.1963\n",
      "Epoch [2/5], Step [300/600], Loss: 1.8385\n",
      "Epoch [2/5], Step [400/600], Loss: 1.7665\n",
      "Epoch [2/5], Step [500/600], Loss: 1.2371\n",
      "Epoch [2/5], Step [600/600], Loss: 0.8061\n",
      "Epoch [3/5], Step [100/600], Loss: 0.6483\n",
      "Epoch [3/5], Step [200/600], Loss: 0.2122\n",
      "Epoch [3/5], Step [300/600], Loss: 0.9735\n",
      "Epoch [3/5], Step [400/600], Loss: 1.4017\n",
      "Epoch [3/5], Step [500/600], Loss: 1.5472\n",
      "Epoch [3/5], Step [600/600], Loss: 0.9270\n",
      "Epoch [4/5], Step [100/600], Loss: 0.1544\n",
      "Epoch [4/5], Step [200/600], Loss: 0.2308\n",
      "Epoch [4/5], Step [300/600], Loss: 0.5136\n",
      "Epoch [4/5], Step [400/600], Loss: 0.8091\n",
      "Epoch [4/5], Step [500/600], Loss: 0.7876\n",
      "Epoch [4/5], Step [600/600], Loss: 0.5452\n",
      "Epoch [5/5], Step [100/600], Loss: 0.2013\n",
      "Epoch [5/5], Step [200/600], Loss: 0.3206\n",
      "Epoch [5/5], Step [300/600], Loss: 1.2882\n",
      "Epoch [5/5], Step [400/600], Loss: 0.7557\n",
      "Epoch [5/5], Step [500/600], Loss: 1.1387\n",
      "Epoch [5/5], Step [600/600], Loss: 0.6463\n",
      "elapsed:  124.7371141910553\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.514803417523702\n",
      "torch.Size([500, 100])\n",
      "np.count_nonzero(output_relu)= 21412\n",
      "sparsity 0.57176\n",
      "Accuracy of the network on the 10000 test images: 94.79 %\n"
     ]
    }
   ],
   "source": [
    "def relu_diff(input1, input2):\n",
    "    '''this is sparse: two level-relu'''\n",
    "    return torch.max(input1 - input2, torch.zeros_like(input1))\n",
    "    \n",
    "class ReLU_my(nn.Module):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    References:\n",
    "        -  Related paper:\n",
    "        https://arxiv.org/pdf/1606.08415.pdf\n",
    "    Examples:\n",
    "        >>> m = silu()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__() # init the base class\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return relu_diff(input1, input2)\n",
    "\n",
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "#         m.weight.data.normal_(0.0, 1)#93% accuracy for relu; \n",
    "#         m.weight.data.normal_(-1, 1)# 11% accuracy for relu; 93.62 for this idea. \n",
    "        m.weight.data.normal_(1, 1)#92.87\n",
    "    \n",
    "def weights_sparse(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "#         init.sparse_(m.weight.data, 0.3, 0.01)\n",
    "#         init.sparse_(m.weight.data, 0.7, 0.01)\n",
    "        init.sparse_(m.weight.data, 0.7, 0.1)\n",
    "#         init.sparse_(m.weight.data, 0.7, 1.0)#worse\n",
    "    \n",
    "# print(np.random.binomial(1, 0.5, 5))\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = ReLU_my()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        out1 = self.fc1(out)\n",
    "        out2 = self.fc2(out)\n",
    "        \n",
    "        out_relu = self.relu(out1, out2)\n",
    "        out = self.fc3(out_relu)\n",
    "        return out, out_relu  \n",
    "#optionally add a sigmoid to the blocking; not sparse\n",
    "#     def forward(self, x):\n",
    "#         out = x\n",
    "        \n",
    "#         out1 = self.fc1(out)\n",
    "#         out2 = self.fc2(out)\n",
    "#         out2 = self.sigmoid(out2)\n",
    "        \n",
    "#         out_relu = self.relu(out1, out2)\n",
    "#         out = self.fc3(out_relu)\n",
    "#         return out, out_relu  \n",
    "\n",
    "#now I can define my model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "# model.apply(weights_init)\n",
    "model.apply(weights_sparse)\n",
    "\n",
    "#visualzing graphs\n",
    "# writer=SummaryWriter('runs/experiment_1')\n",
    "# dataiter=iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(images.shape)\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# #writer.add_image('images', grid, 0)\n",
    "\n",
    "# #images = images.reshape(-1, 28*28).to(device)\n",
    "# dummy_input = torch.zeros(1, 28*28),\n",
    "# writer.add_graph(model, dummy_input)\n",
    "# writer.close()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, _  = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "\n",
    "print('elapsed: ', time.time()-start)\n",
    "plt.plot(losses, '-b+')\n",
    "plt.show()\n",
    "print(np.mean(losses))\n",
    "\n",
    "#check dead neurons\n",
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.reshape(-1, 28*28).to(device)\n",
    "# print(images.shape)\n",
    "A1 = images[:300]\n",
    "# print(A1.shape)\n",
    "output, output_relu = model(A1)\n",
    "\n",
    "output_relu = output_relu.T.detach()\n",
    "print(output_relu.shape)\n",
    "# plt.plot(output_relu.numpy(), '-b+')\n",
    "# plt.show()\n",
    "print('np.count_nonzero(output_relu)=', np.count_nonzero(output_relu))\n",
    "print('sparsity', 1- np.count_nonzero(output_relu)/ (output_relu.shape[0] * output_relu.shape[1]))\n",
    "\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "labels_wrong = []\n",
    "pred_wrong = []\n",
    "img_wrong = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, labels in test_loader:\n",
    "#         print(img.shape)\n",
    "        images = img.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        wrong_preds = (predicted != labels).numpy()\n",
    "        wrong_index = []\n",
    "        for (i, wrong) in enumerate(wrong_preds):\n",
    "            if wrong:\n",
    "                wrong_index.append(i) \n",
    "        if len(wrong_index) > 0:\n",
    "            img_reshaped = img[wrong_index].numpy()[:,0,:,:]\n",
    "            for img_w in range(img_reshaped.shape[0]):\n",
    "                img_wrong.append(img_reshaped[img_w])\n",
    "            labels_wrong  += (labels[wrong_index].numpy().tolist())\n",
    "            pred_wrong += (predicted[wrong_index].numpy().tolist())\n",
    "#     print(img_wrong)\n",
    "#     print('img_wrong.shape', img_wrong[0].shape)\n",
    "#     print('lables_wrong =', labels_wrong)\n",
    "#     print('predictions wrong are:', pred_wrong)\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "#show wrong images:\n",
    "# print(len(img_wrong), ', ', len(labels_wrong), ', ', len(pred_wrong))\n",
    "# for i in range(len(img_wrong)):\n",
    "#     plt.imshow(img_wrong[i])\n",
    "#     print('labels_wrong[i]:', labels_wrong[i])\n",
    "#     print('pred_wrong[i]', pred_wrong[i])\n",
    "#     plt.pause(1)\n",
    "\n",
    "# Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.5779,  0.0640,  0.1430, -0.1617, -0.5140,  0.3530,  0.5737, -0.1477,\n",
      "          0.1958, -0.1691],\n",
      "        [ 0.4743,  0.2682, -0.5371, -0.1988,  0.2150, -0.6793, -0.1516,  0.6180,\n",
      "         -0.3148, -0.7621],\n",
      "        [ 0.2593, -0.1268, -0.0784,  0.0650,  0.3511, -0.3761,  0.4965, -0.7066,\n",
      "          0.4375, -0.4512],\n",
      "        [-0.4706,  0.6136, -0.5341, -0.2328,  0.5161, -0.2980, -0.2179, -0.1023,\n",
      "          0.1481,  0.2383],\n",
      "        [ 0.0301, -0.7920,  0.7271, -0.2208,  0.5299,  0.3283, -0.6619, -0.1630,\n",
      "         -0.1853, -0.2730],\n",
      "        [-0.7178, -0.2460, -0.3829, -0.0773,  0.0664,  0.3904, -0.1010,  0.4212,\n",
      "          0.1781,  0.1411],\n",
      "        [ 0.1937, -0.3704,  0.1585, -0.1834, -0.6606,  0.0736, -0.4391,  0.3063,\n",
      "          0.6534, -0.7792],\n",
      "        [ 0.3262,  0.5748,  0.1930, -0.1342, -0.3776,  0.3556,  0.1013, -0.6247,\n",
      "         -0.7301,  0.2556],\n",
      "        [ 0.2724, -0.5699, -0.5487,  0.0173,  0.0711,  0.0028, -0.0344,  0.0607,\n",
      "          0.2700,  0.4230],\n",
      "        [ 0.1526, -0.0439,  0.4754, -0.0905, -0.4418, -0.4576, -0.2354,  0.1002,\n",
      "         -0.1119,  0.6380]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3967,  0.0543,  0.1003,  0.0194,  0.2582,  0.5695,  0.0319,  0.3185,\n",
      "        -0.4473, -0.1333], requires_grad=True)]\n",
      "layer 1:\n",
      "[Parameter containing:\n",
      "tensor([[ 0.0190,  0.0344, -0.0007,  ...,  0.0145, -0.0254,  0.0243],\n",
      "        [-0.0303,  0.0309,  0.0042,  ..., -0.0326, -0.0123, -0.0125],\n",
      "        [-0.0008, -0.0013,  0.0232,  ...,  0.0080,  0.0222, -0.0120],\n",
      "        ...,\n",
      "        [-0.0047, -0.0164,  0.0308,  ..., -0.0316, -0.0282,  0.0220],\n",
      "        [-0.0104, -0.0291,  0.0317,  ...,  0.0341,  0.0170, -0.0170],\n",
      "        [ 0.0081,  0.0353,  0.0004,  ..., -0.0056, -0.0110, -0.0028]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0456,  0.3276,  0.2901,  0.0216,  0.0949,  0.2920,  0.0664,  0.2952,\n",
      "        -0.2474, -0.2152], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print('layer 1:')\n",
    "w_fc1 = list(model.fc1.parameters())\n",
    "print(w_fc1)\n",
    "\n",
    "print('layer 2:')\n",
    "w_fc2 = list(model.fc2.parameters())\n",
    "print(w_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.12 %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#future work\n",
    "def relu_at(A, threshold):\n",
    "    return torch.max(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "def relu_min_at(A, threshold):\n",
    "    return torch.min(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "class ThresholdingNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ThresholdingNet2, self).__init__()\n",
    "        self.maxlu = ReLU_my()\n",
    "        self.minlu = ReLU_min()\n",
    "        self.fc1 = nn.Linear(input_size*2, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        out1 = self.maxlu(out)\n",
    "        out2 = self.minlu(out)\n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out  \n",
    "    \n",
    "# model = ThresholdingNet(input_size, hidden_size, num_classes).to(device)\n",
    "model = ThresholdingNet2(input_size, hidden_size, num_classes).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
