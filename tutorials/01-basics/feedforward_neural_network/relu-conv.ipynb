{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 800\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "num_workers=0\n",
    "\n",
    "num_epochs = 20#5\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=True,\n",
    "                                   download=False, transform=transform)\n",
    "test_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=False,\n",
    "                                  download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(7*7*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 7*7*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.4)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1) \n",
    "\n",
    "#now I can define my model\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/600], Loss: 0.1829\n",
      "Epoch [1/20], Step [200/600], Loss: 0.1468\n",
      "Epoch [1/20], Step [300/600], Loss: 0.0949\n",
      "Epoch [1/20], Step [400/600], Loss: 0.0850\n",
      "Epoch [1/20], Step [500/600], Loss: 0.1637\n",
      "Epoch [1/20], Step [600/600], Loss: 0.0450\n",
      "Epoch [2/20], Step [100/600], Loss: 0.0938\n",
      "Epoch [2/20], Step [200/600], Loss: 0.0456\n",
      "Epoch [2/20], Step [300/600], Loss: 0.0648\n",
      "Epoch [2/20], Step [400/600], Loss: 0.0981\n",
      "Epoch [2/20], Step [500/600], Loss: 0.1251\n",
      "Epoch [2/20], Step [600/600], Loss: 0.1185\n",
      "Epoch [3/20], Step [100/600], Loss: 0.0808\n",
      "Epoch [3/20], Step [200/600], Loss: 0.0347\n",
      "Epoch [3/20], Step [300/600], Loss: 0.1724\n",
      "Epoch [3/20], Step [400/600], Loss: 0.0688\n",
      "Epoch [3/20], Step [500/600], Loss: 0.0621\n",
      "Epoch [3/20], Step [600/600], Loss: 0.0582\n",
      "Epoch [4/20], Step [100/600], Loss: 0.0231\n",
      "Epoch [4/20], Step [200/600], Loss: 0.0229\n",
      "Epoch [4/20], Step [300/600], Loss: 0.0252\n",
      "Epoch [4/20], Step [400/600], Loss: 0.0656\n",
      "Epoch [4/20], Step [500/600], Loss: 0.0309\n",
      "Epoch [4/20], Step [600/600], Loss: 0.0550\n",
      "Epoch [5/20], Step [100/600], Loss: 0.0909\n",
      "Epoch [5/20], Step [200/600], Loss: 0.0200\n",
      "Epoch [5/20], Step [300/600], Loss: 0.0089\n",
      "Epoch [5/20], Step [400/600], Loss: 0.0331\n",
      "Epoch [5/20], Step [500/600], Loss: 0.0019\n",
      "Epoch [5/20], Step [600/600], Loss: 0.0083\n",
      "Epoch [6/20], Step [100/600], Loss: 0.0127\n",
      "Epoch [6/20], Step [200/600], Loss: 0.0040\n",
      "Epoch [6/20], Step [300/600], Loss: 0.0475\n",
      "Epoch [6/20], Step [400/600], Loss: 0.0342\n",
      "Epoch [6/20], Step [500/600], Loss: 0.0371\n",
      "Epoch [6/20], Step [600/600], Loss: 0.0624\n",
      "Epoch [7/20], Step [100/600], Loss: 0.0213\n",
      "Epoch [7/20], Step [200/600], Loss: 0.0270\n",
      "Epoch [7/20], Step [300/600], Loss: 0.0201\n",
      "Epoch [7/20], Step [400/600], Loss: 0.0398\n",
      "Epoch [7/20], Step [500/600], Loss: 0.0225\n",
      "Epoch [7/20], Step [600/600], Loss: 0.0171\n",
      "Epoch [8/20], Step [100/600], Loss: 0.0162\n",
      "Epoch [8/20], Step [200/600], Loss: 0.0074\n",
      "Epoch [8/20], Step [300/600], Loss: 0.0074\n",
      "Epoch [8/20], Step [400/600], Loss: 0.0073\n",
      "Epoch [8/20], Step [500/600], Loss: 0.0217\n",
      "Epoch [8/20], Step [600/600], Loss: 0.0261\n",
      "Epoch [9/20], Step [100/600], Loss: 0.0028\n",
      "Epoch [9/20], Step [200/600], Loss: 0.0008\n",
      "Epoch [9/20], Step [300/600], Loss: 0.0149\n",
      "Epoch [9/20], Step [400/600], Loss: 0.0116\n",
      "Epoch [9/20], Step [500/600], Loss: 0.0468\n",
      "Epoch [9/20], Step [600/600], Loss: 0.0291\n",
      "Epoch [10/20], Step [100/600], Loss: 0.0029\n",
      "Epoch [10/20], Step [200/600], Loss: 0.0008\n",
      "Epoch [10/20], Step [300/600], Loss: 0.0158\n",
      "Epoch [10/20], Step [400/600], Loss: 0.0078\n",
      "Epoch [10/20], Step [500/600], Loss: 0.0077\n",
      "Epoch [10/20], Step [600/600], Loss: 0.0118\n",
      "Epoch [11/20], Step [100/600], Loss: 0.0091\n",
      "Epoch [11/20], Step [200/600], Loss: 0.0030\n",
      "Epoch [11/20], Step [300/600], Loss: 0.0057\n",
      "Epoch [11/20], Step [400/600], Loss: 0.0161\n",
      "Epoch [11/20], Step [500/600], Loss: 0.0041\n",
      "Epoch [11/20], Step [600/600], Loss: 0.0062\n",
      "Epoch [12/20], Step [100/600], Loss: 0.0015\n",
      "Epoch [12/20], Step [200/600], Loss: 0.0036\n",
      "Epoch [12/20], Step [300/600], Loss: 0.0007\n",
      "Epoch [12/20], Step [400/600], Loss: 0.0002\n",
      "Epoch [12/20], Step [500/600], Loss: 0.0042\n",
      "Epoch [12/20], Step [600/600], Loss: 0.0024\n",
      "Epoch [13/20], Step [100/600], Loss: 0.0038\n",
      "Epoch [13/20], Step [200/600], Loss: 0.0037\n",
      "Epoch [13/20], Step [300/600], Loss: 0.0501\n",
      "Epoch [13/20], Step [400/600], Loss: 0.0124\n",
      "Epoch [13/20], Step [500/600], Loss: 0.0006\n",
      "Epoch [13/20], Step [600/600], Loss: 0.0011\n",
      "Epoch [14/20], Step [100/600], Loss: 0.0020\n",
      "Epoch [14/20], Step [200/600], Loss: 0.0043\n",
      "Epoch [14/20], Step [300/600], Loss: 0.0011\n",
      "Epoch [14/20], Step [400/600], Loss: 0.0031\n",
      "Epoch [14/20], Step [500/600], Loss: 0.0028\n",
      "Epoch [14/20], Step [600/600], Loss: 0.0042\n",
      "Epoch [15/20], Step [100/600], Loss: 0.0026\n",
      "Epoch [15/20], Step [200/600], Loss: 0.0002\n",
      "Epoch [15/20], Step [300/600], Loss: 0.0292\n",
      "Epoch [15/20], Step [400/600], Loss: 0.0190\n",
      "Epoch [15/20], Step [500/600], Loss: 0.0002\n",
      "Epoch [15/20], Step [600/600], Loss: 0.0257\n",
      "Epoch [16/20], Step [100/600], Loss: 0.0002\n",
      "Epoch [16/20], Step [200/600], Loss: 0.0003\n",
      "Epoch [16/20], Step [300/600], Loss: 0.0008\n",
      "Epoch [16/20], Step [400/600], Loss: 0.0018\n",
      "Epoch [16/20], Step [500/600], Loss: 0.0001\n",
      "Epoch [16/20], Step [600/600], Loss: 0.0003\n",
      "Epoch [17/20], Step [100/600], Loss: 0.0125\n",
      "Epoch [17/20], Step [200/600], Loss: 0.0040\n",
      "Epoch [17/20], Step [300/600], Loss: 0.0068\n",
      "Epoch [17/20], Step [400/600], Loss: 0.0006\n",
      "Epoch [17/20], Step [500/600], Loss: 0.0126\n",
      "Epoch [17/20], Step [600/600], Loss: 0.0034\n",
      "Epoch [18/20], Step [100/600], Loss: 0.0006\n",
      "Epoch [18/20], Step [200/600], Loss: 0.0132\n",
      "Epoch [18/20], Step [300/600], Loss: 0.0296\n",
      "Epoch [18/20], Step [400/600], Loss: 0.0114\n",
      "Epoch [18/20], Step [500/600], Loss: 0.0004\n",
      "Epoch [18/20], Step [600/600], Loss: 0.0114\n",
      "Epoch [19/20], Step [100/600], Loss: 0.0001\n",
      "Epoch [19/20], Step [200/600], Loss: 0.0022\n",
      "Epoch [19/20], Step [300/600], Loss: 0.0002\n",
      "Epoch [19/20], Step [400/600], Loss: 0.0008\n",
      "Epoch [19/20], Step [500/600], Loss: 0.0121\n",
      "Epoch [19/20], Step [600/600], Loss: 0.0090\n",
      "Epoch [20/20], Step [100/600], Loss: 0.0002\n",
      "Epoch [20/20], Step [200/600], Loss: 0.0106\n",
      "Epoch [20/20], Step [300/600], Loss: 0.0002\n",
      "Epoch [20/20], Step [400/600], Loss: 0.0002\n",
      "Epoch [20/20], Step [500/600], Loss: 0.0020\n",
      "Epoch [20/20], Step [600/600], Loss: 0.0000\n",
      "elapsed:  73235.12906908989\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2deZwdZZX3fyedzr4nTVayQYwExGA6YScKRoNLwkdBE5FlxGH0hRlnXIbwKskN6vCi4+CgjIgigqAEUceoQEbBOMgS0oEQSEJIEwI02elO0mTv7vP+cepYz62uurfu7bt2ne/ncz9V9dRTVU/Vvff51TnnWYiZYRiGYSSPHuUugGEYhlEeTAAMwzASigmAYRhGQjEBMAzDSCgmAIZhGAmlZ7kLkAsjRozgiRMnlrsYhmEYVcWaNWv2MHNdML2qBGDixIloaGgodzEMwzCqCiJ6LSzdXECGYRgJxQTAMAwjoZgAGIZhJBQTAMMwjIRiAmAYhpFQEiMAqVS5S2AYhlFZJEYAli4tdwkMwzAqi0QIwL33lrsEhmEYlUe3FoBUCiACLrtMtonkY+4gwzCMBAgAM3D55bLNLB8TAMMwjG4uAMrQoeUugWEYRuWRKAFoby9vOQzDMCqJRAjAkCGy3Lu3vOUwDMOoJBIhAGoBtLSUtxyGYRiVRCwBIKK5RLSJiBqJaFHI/vOI6FkiaiOii5309xHRWudzmIgu8vb9lIhedfZNL9xtpaMCYBaAYRiGT9b5AIioBsBtAOYAaAKwmoiWM/MGJ9vrAK4E8GX3WGb+M4Dp3nmGAWgE8D9Olq8w84NduYE4mAVgGIbRmTgTwswC0MjMWwCAiO4HMB/A3wSAmbd6+zoynOdiAA8z88G8S5snGgMwATAMw/CJ4wIaC+ANZ7vJS8uVBQB+EUj7JhGtI6JbiKh32EFEdDURNRBRw+7du/O4bGVaANYXwTCMchNHACgkjXO5CBGNBvAuACuc5OsBvBPATADDAFwXdiwz38HM9cxcX1fXaUrLWFSaABw5YmMTGYZRfuIIQBOA453tcQC25XidTwD4DTMf0wRm3s7CEQB3QVxNRaFvX6BXr8oJAp99drlLYBiGEU8AVgOYQkSTiKgXxJWzPMfrLETA/eNZBSAiAnARgBdzPGdsiMQKKLcFoGMTrVkj2zY2kWEY5SSrADBzG4BrIe6bjQAeYOb1RHQjEc0DACKaSURNAC4B8EMiWq/HE9FEiAXxl8Cp7yOiFwC8AGAEgG90/XaiGTKkMgSA2Q9K29hEhmGUkzitgMDMDwF4KJC22FlfDXENhR27FSFBY2Y+P5eCdpVKsACUY8ey5zEMwyg2iegJDFSWALS1AVOnlrsUhmEknUQJQKUEgdvagMmTy10KwzCSTqIEoBIsAGYZlfTo0XKXxDCMpJMYARgyRCyAjkx9lVH8gGxbmyxNAAzDKDeJEYChQ6Xyb23NnK/YHbQ0AGwCYBhGuUmUAACZ3UANDbLknPo554ZZAIZhVAqJE4CwQLB20Jo5U7Z79CheBy0VAGsKahhGuUmMAGQaEVQ7aC3yZjrYt694HbTMBWQYRqWQGAGI4wI6ckSWxXw7NxeQYRiVggmAw+HDsiymAJgFYBhGpWAC4FAKATALwDCMSiExAjBwoAR3zQVkGIYhJEYAiPzOYFGYC8gwjCSRGAEAsg8HUUoXkDUDNQyj3JgAOKgLqJhv51rxt7fLxzAMo1yYADiU0gIo9nUMwzCyYQLgUGoBsDiAYRjlJFECkC0IXIpWQO65TQAMwygnsQSAiOYS0SYiaiSiRSH7zyOiZ4mojYguDuxrJ6K13me5kz6JiFYR0WYiWuZNOF9U1AKIGuzNLADDMJJEVgEgohoAtwG4EMA0AAuJaFog2+sArgTw85BTHGLm6d5nnpN+M4BbmHkKgBYAV+VR/pwYOlQq94MHw/eXshlosa9jGIaRjTgWwCwAjcy8hZmPArgfwHw3AzNvZeZ1ALJMtyIQEQE4H8CDXtLdAC6KXeo8ydYb2CwAwzCSRBwBGAvgDWe7yUuLSx8iaiCip4lIK/nhAPYys1aHkeckoqu94xt2796dw2U7oyOCfvOb4ftL2RMYMAEwDKO8xBEACknLZcqU8cxcD+BTAL5LRCfkck5mvoOZ65m5vq6uLofLdkYtgNtvD99faheQCYBhGOUkjgA0ATje2R4HYFvcCzDzNm+5BcBKAKcB2ANgCBH1zOec+aICEEZHh185mwVgGEYSiCMAqwFM8Vrt9AKwAMDyLMcAAIhoKBH19tZHADgbwAZmZgB/BqAthq4A8NtcC58LqZQ/45eUJ33WL3X/AKXpCVzs6xiGYWQjqwB4fvprAawAsBHAA8y8nohuJKJ5AEBEM4moCcAlAH5IROu9w08C0EBEz0Mq/P/HzBu8fdcB+CIRNUJiAncW8saCpFLA9u3ufaXP+qXuH8AsAMMwkkHP7FkAZn4IwEOBtMXO+mqIGyd43JMA3hVxzi2QFkYlo3//6H3lEABrBmoYRjlJVE/gfv1kOXt2532uC8iCwIZhJIFECUBNjYhAfX3nfeYCMgwjaSRKAABxA739duf0UgmAWQCGYVQKiROAAQOAAwc6p5fKBWQWgGEYlUIiBaCcFoAJgGEYlULiBKCSXEDWCsgwjHKSOAEwF5BhGIaQSAHIZgEUuydwTU3xr2MYhpGNxAlAuV1AbW1+fwQTAMMwykniBCDKBaQC0KtX8QWgTx8Zh8gEwDCMcpJIAQizADQGMGBA8YPAPXuK0JgAGIZRThInAP37y5SQHYG5y9QCGDiw+BZAba0JgGEY5SdxAjBggCyD8wKXSgBcC8CagRqGUU4SKwBBN9CRI9I6p0+f4lsA5gIyDKMSSJwA6JDQQQE4fFgq/9pacwEZhpEMEicAagEEWwIdPgz07l18AbAgsGEYlUJiBSDMBaQWQDErZrUAin0dwzCMbCROAMrtAjILwDCMSiGWABDRXCLaRESNRLQoZP95RPQsEbUR0cVO+nQieoqI1hPROiL6pLPvp0T0KhGt9T7TC3NLmcnkAurTp+utc3SO4SjcILC1AjIMo5xkFQAiqgFwG4ALAUwDsJCIpgWyvQ7gSgA/D6QfBHA5M58MYC6A7xLREGf/V5h5uvdZm+c95EQmF1BXYwDMwNKlmfNYENgwjEohjgUwC0AjM29h5qMA7gcw383AzFuZeR2AjkD6y8y82VvfBmAXgLqClDxPiuUCam4Ghg3Lns9cQIZhVApxBGAsgDec7SYvLSeIaBaAXgBecZK/6bmGbiGi3hHHXU1EDUTUsHv37lwv24lsLqB8BCCVAoYPB/bu1TLLJ8wdZBaAYRiVQhwBoJA0zuUiRDQawM8A/B0zq5VwPYB3ApgJYBiA68KOZeY7mLmemevr6rpuPOhInGEWQL4uoFQK+N3v/O1du8QdFCYAZgEYhlEpxBGAJgDHO9vjAGyLewEiGgTgDwC+xsxPazozb2fhCIC7IK6motOjh4hApmag+biAdu3y1x94IDqfBoGtGahhGOUmjgCsBjCFiCYRUS8ACwAsj3NyL/9vANzDzL8M7BvtLQnARQBezKXgXSFsSOiuxgBUAIYNA+69NzrfsWO+C8haARmGUU6yCgAztwG4FsAKABsBPMDM64noRiKaBwBENJOImgBcAuCHRLTeO/wTAM4DcGVIc8/7iOgFAC8AGAHgGwW9swyEDQnd1Z7AO3fKeRctAp5+GvinfwrPZ2MBGYZRKfSMk4mZHwLwUCBtsbO+GuIaCh53L4DQ92FmPj+nkhaQsFnButoTeNcuYORIYOFC4LrrgO99D7j11s75rCewYRiVQuJ6AgOZXUD5umZ27gSOOw4YNw543/ui81kQ2DCMSiGxApDJBcQMtLfnds5du6QvABHw2GOSFtYc1JqBGoZRKSRSAIIuIOZ0FxCQuxWwaxcwe7ac66abJO3Qoc7NQdUCMBeQYRjlJpECEHQBaUWcrwC0twO7d4sLCACGeINdaMcwFwsCG4ZRKSRWAFwLQKeDzFcAmptljuGRI2U7mwCoCygfV5NhGEahMAGAuH8APwYA5CYAO3fKMo4F4AaBAbMCDMMoH4kUgP79xT+vb99dtQC0E1g2AdA3frUAABMAwzDKRyIFQAeEO3hQloUSgGwuoLY2WZoFYBhGJZBoAVA3kApAsV1AJgCGYVQSsXoCdzd0TgBtCaQxgD59JJgL5FYx79ollfrQobKdTQC0J3Cu1zEMwygkZgGg6y6gnTuBujoZaVTP07t3ZwHQc7oWgA0IZxhGuTABQNddQDoOkMuQIZktAHMBGYZRbhIpAJlcQPkKgPr/lTABCLMATAAMwygXiRSAYriAwgSgpSU9zYLAhmFUEiYAMBeQYRjJJJECUEgX0NtvS3+CXF1A1grIMIxyk0gBKKQLKNgJTDELwDCMSieRAtC3r4zTX0gBiLIAmP00awZqGEYlEUsAiGguEW0iokYiWhSy/zwiepaI2ojo4sC+K4hos/e5wkmfQUQveOe81ZscviT06AH069fZBeTGAOK+mQd7AStDhsg5VFwACwIbhlFZZBUAIqoBcBuACwFMA7CQiKYFsr0O4EoAPw8cOwzAEgCnA5gFYAkRef1l8QMAVwOY4n3m5n0XeeCOCHr4sFgErmumEC4gIN0NZC4gwzAqiTgWwCwAjcy8hZmPArgfwHw3AzNvZeZ1ADoCx34QwB+ZuZmZWwD8EcBcIhoNYBAzP8XMDOAeABd19WZyISgAffr4IgDkLgB1denpOiyEKwDWD8AwjEoijgCMBfCGs93kpcUh6tix3nrWcxLR1UTUQEQNu3fvjnnZ7PTvn+4C6t1b1nMVAHUB6fGKWQCGYVQ6cQQgzDfPIWm5HBv7nMx8BzPXM3N9XfA1uwuEWQBA/hZAkDABsGaghmFUEnEEoAnA8c72OADbYp4/6tgmbz2fcxaEAQOAl16S9XwEIJUSl9GyZbJNJB+dAD6TBWCtgAzDqATiCMBqAFOIaBIR9QKwAMDymOdfAeADRDTUC/5+AMAKZt4OoJWIzvBa/1wO4Ld5lD9v+vcH3nxT1g8fzt0FlEpJE8/TTpNtZvnEEQBzARmGUQlkFQBmbgNwLaQy3wjgAWZeT0Q3EtE8ACCimUTUBOASAD8kovXesc0Avg4RkdUAbvTSAODzAH4MoBHAKwAeLuidZUE7gwESA8hkAWilHkZzc3j64MGyNBeQYRiVSqwJYZj5IQAPBdIWO+urke7ScfP9BMBPQtIbAJySS2ELQSoFLF3qb2vvg7FeCLqmRpZaWTNL/igRaG4Gzjijc3qfPvKJsgBqauRjAmAYRrlIXE9gdd3cf79sP/MMMHs2cMIJsq1NQVUAHnlEltrax+XoUaC1Ffjwh8OvFRwOwrUAAHEDmQAYhlEuEicAyrnnyvLxx9NdQIBUzCtXihh86EOSNmpUepAX8Id7HjYs/BpBAXCDwIAITTEFIJPryjAMI7ECMGaMVNCPP57eCgiQinnmTLEUvvUtSXv88fQgL+D7/4cPD79GlACo/7/YFoDr6jIMwwiSWAEAgPnzgb/+FTh0qLMAqLumtVWW2mfARQUgrgUQ5gIqVjPQ55+X5Z49xTm/YRjVT6IF4NxzpYJ85ZX0nryuAGjFr0LgkqsAlMIC0P4J06fLdl1dZ9eVYRgGYAIAQCrmfCyAt96SZVcsgGIIADPwne/IdpjryjAMA0i4AEyZ4g/jHCUAhbAAdE6AYBC4mDEAFZ5Dh4pzfsMwqp9ECwCRbwU0NPjpuQhATQ0waFD4+XVOAK2ESxkE1hZK7nwEhmEYLokWAMAXgKee8tNyCQIPG+Z3JgsSHA4i6AIqZjNQFQCzAAzDiMIE4NzOaXEtgLfeinb/AJ0FoK1NLAYVjGK2AjILwDCMbCRaAFIpYMYMf1tH9NyxIzcLIIowC6CnM/hGKVxAZgEYhhFF4gVAR/EE/PUTTvAr5mwxgFwtgFILgFkAhmFEkWgBiCIsBhAlAFG9gAFfAO68U5ZtbX4AGDALwDCM8mIC4LFkib+uAsDsWwBdcQH9+teyLJULiNksAMMwsmMC4OF2lFIBOHTIdw8FLYBjx4D9++MJgFIqC+DQIf+8ZgEYhhGFCUAIKgBupR+0ALKNBJpKpXcuIwJ+9CN/Inr3OoVGywaYABiGEY0JQAhaMWulP3BgZwsgWy9gDTBrjIAZ+PSn02MGxbIA3OEnzAVkGEYUJgAhBC2A0aM7WwDZhoJWBg7010vlAjILwDCMOMQSACKaS0SbiKiRiBaF7O9NRMu8/auIaKKXfikRrXU+HUQ03du30jun7juukDfWFYIWwKhRMmmM667JZgEoAwcCU6fKeqmCwK4AmAVgGEYUWQWAiGoA3AbgQgDTACwkommBbFcBaGHmEwHcAuBmAGDm+5h5OjNPB3AZgK3MvNY57lLdz8y7CnA/BSEoAKNHy9J1A2UbCVQZOBAY582WXGoLYPBgswAMw4gmjgUwC0AjM29h5qMA7gcwP5BnPoC7vfUHAVxA1GmEnIUAftGVwpYKrZhdFxCQ7gbKxQLQ80RZANrSqFCoAIwZYxaAYRjRxBGAsQDecLabvLTQPMzcBmAfgKB3/JPoLAB3ee6fG0IEAwBARFcTUQMRNezevTtGcbtOHAuguRno0SN6JFBl0CBpLgp07gms1oCOElooVABGjjQLwDCMaOIIQFjFHHxnzZiHiE4HcJCZX3T2X8rM7wJwrve5LOzizHwHM9czc31dXV2M4nadsCAw0NkCGDZMRCATQQsg6ALS9ELS0iLC07+/WQCGYUQTRwCaABzvbI8DsC0qDxH1BDAYQLOzfwECb//M/Ka3bAXwc4irqSKIGwPI5v4B0gUgbCwgoPBxgJYWYOhQoG9fswAMw4gmjgCsBjCFiCYRUS9IZb48kGc5gCu89YsBPMYsnm0i6gHgEkjsAF5aTyIa4a3XAvgIgBdRIdTWAh0dwL59UmFrU88wCyAbAwfKcczhQWCgeALQp48JgGEY0fTMloGZ24joWgArANQA+AkzryeiGwE0MPNyAHcC+BkRNULe/Bc4pzgPQBMzb3HSegNY4VX+NQD+BOBHBbmjAqCVdEuLVODalj8YAxg5Mvu5Bg4UMTl4MDwIDBTXAjAXkGEYUWQVAABg5ocAPBRIW+ysH4a85YcduxLAGYG0AwBmhOWvBFwBGDAgWgBOOin7udxjS+UC2rtX+h6YC8gwjExYT+AQghbAgAGyHXQBZesFDKQLQDAIrGMFuR23CoHrAjILwDCMKEwAQtBKurlZKv9+/WQwNzeYu29fvBiANhPdv9+3AFIpOd8nPyn76utl2x2RNC5hx7guoCNHxAVlGIYRxAQghKAAEMlSLQB9Y3/66eznCrqAams7z0Q2caJU0vkIwNKl6dtHjojbRy0ATTMMwwhiAhCC+uabm/0K3G3Oqb2AH344+7mCLqCeIVGXrVuBJ5/MvZyLF3dOU3EaMkQsAMDiAIZhhGMCEIJaAK2tvv9fm3MC/jhAccgUBAaA668XF9O998Y/p7qQvv512dbJ7FMpXwBcC8DiAIZhhGECEIIbqNUKfMAAqcRTKeDss/39buUbRqYgMAD8278B8+cDDzwA3HBDvPKlUsCOHf62upOCAlAOCyAfN5ZhGOXBBCAEt5J2LQAVgG9/29/vVr5hZLMAAJkoprkZ+MY34pdx377w9DALoFQCsG1b55iEYRiViwlACFEWgLqAtm7tPN9vFP37y9INAgeZMwfIdZgjFYCJE9PTwyyAUriAXnkFOP747PkMw6gcTABCyGQBAMBrrwETJgBLlmQ/V48ecuz+/eFB4FRKgs460Gk2l5KiAjB4cHp6OSyAVAo48US/uWncezAMo7yYAIQQJgCuBaACELeCU/EIcwFpk1B9Sz/hhHgVtgpAsBOZzgfstgIqtgWQSgF33eVvZ3OLGYZRGZgAhBDmAtJKnFlcQEHXSyZcAQhzAQFA796yfOUV4Fvfyu5L1zkGggKgw1fU1pY2COwGpQ3DqA5ijQWUNKIsgAMHJFjb2ioWQFwGDvQr6rAgsLJkCfDSS9IyKBtqAQRbF7W0+PGJUjYDVQE488ziX8swjMJgFkAI2hEMSLcAAGD9elnmagGoAERZAMqyZX7P3Uy+dLcVkLp9AH8YCKA8FsAppxT/WoZhFAYTgBCigsAA8KI3a0ExLIBUCtjiDJqdyZfuCkCzM/VOS4u/rxwWQFTzVMMwKg8TgBCiXECALwC5WgBaSWcSAMB/e8+GW9G6cYCWFuD112W9lBbA9u2y1NiEYRiVj8UAQogKAgPiAurfP95IoMqgQb6bJpsLaNAgcfucc07mfFEWgLteyo5gZgEYRvVhFkAI2SyACROkko7LwIH+yJ/ZLIAePcQKOPXUzPnc4ahbWvzxgd58U9KIZIwhoPguoIMH/Td/EwDDqB5MAELIFANobs7N/eMeGzx3FEOHZp8kZt8+YNIkWVcB2LnT36/xg969i28B6HV79jQBMIxqIpYAENFcItpERI1EtChkf28iWubtX0VEE730iUR0iIjWep/bnWNmENEL3jG3EuXyTl1ctJLu2xeoqZF1FQIgtwAwkC4A2SwAQATAdeWEsW+fXw7Nq354l1LMC6zun8mTLQZQSVhHPCMbWQWAiGoA3AbgQgDTACwkommBbFcBaGHmEwHcAuBmZ98rzDzd+3zOSf8BgKsBTPE+c/O/jcKiAuBW+m4l3hULIK4AxLEAhg9Pb2GkAvB3f+fn69On+BaACsDUqdIvob29uNcz4mED8xnZiGMBzALQyMxbmPkogPsBzA/kmQ/gbm/9QQAXZHqjJ6LRAAYx81PMzADuAXBRzqUvEioAbsVdKAugkC6gwYPTrQUVgK99zc9XSgtg6lRZ6phJRvl45BFZHj1a3nIYlU0cARgL4A1nu8lLC83DzG0A9gHQKdMnEdFzRPQXIjrXyd+U5ZwAACK6mogaiKhht46YVmTCLIBSuoCGDcssAEePSqU+eHB6XhWA0aP9vH37FtYCCHMr7NghQecTT5TtaokDdEcXiTYGuPBC2e7d2wbmM6KJIwBhb/IcM892AOOZ+TQAXwTwcyIaFPOcksh8BzPXM3N9Xa5jJueJVtLBilvb1efqAtKJ4YH4FkBzs99yKIg7EmjQAhg82C8nIC6gQlkABw6EuxV27JDhrLVVUrXEAbqji0QHF7zuOtl+8UUbmM+IJo4ANAFwR3ofB2BbVB4i6glgMIBmZj7CzG8BADOvAfAKgHd4+cdlOWfZIJKKOjjA2YABEhQ+7rjczpdPDKC93R99NIgrAK4FsG1b+ts/UFgL4IILwtN37ABGjfKHpq4GC6CpKXueakbdcO4wIYYRJI4ArAYwhYgmEVEvAAsALA/kWQ7gCm/9YgCPMTMTUZ0XRAYRTYYEe7cw83YArUR0hhcruBzAbwtwPwWjtlZG5nQZOFAq5h45Np7NRwCAaDdQ0AJwXUBjxqTnLUQQWN0Kq1bJdnCMomoSAL0Xnbymu85doAKQLZZkJJusVZnn078WwAoAGwE8wMzriehGIprnZbsTwHAiaoS4erSp6HkA1hHR85Dg8OeYWRs4fh7AjwE0QiyDhwt0TwUhzFUTd5iGIPkEgYF4AjBsWLoLKMwC6KoLSN0KOmT10aPpboVqEwBmYOZM2e7o6J4uErMAjDjEGgqCmR8C8FAgbbGzfhjAJSHH/QrAryLO2QCg4saOTKXSfcNhbZk0bcmSeBVHPkFgIL4FcOSI9MYNE4BCNQM9csQfpfTll4GTT5Z1Zl8ANNZRDTEAfbZvvQWMGFHeshQDEwAjDtYTOIC+IWoAVtfD0uK+Nfbq5Q8xnYsFENUZLCgAAPDqq1JBF8MCANKbdq5b56/v3SsWQbVYAIoKQNDN110wATDiYAJQItQKKHQMQK0FnaegWBaA+1b/wgv+ugbKR42SsYdqaipfADo6/GfrDr/dndDvywTAyIQJQAbCJn2PMxF8GOoeKaQADBrk540SgEJZAHEEgEhEKY4AlNPn3trqT2DfXQXALAAjDiYAGQirpPKtuNQCiOMCGjhQ3qQzCUC/fnIutQA2bJBlsSwArVCOOy7dBeQKACCiFCcGUM42+O5zNReQkWRMAEpELi4goszDQegwEEBnCyDYDLRvX/HR6xtvvmilfvbZMuGMvuUHBSCOBfDFL3atLF3Ffa7d0QJg9vuQmAAYmTABKBG5WABA5hFBXQFQC2DzZpmoxm1xBPi9grvqBlIB0IlqdGa0HTukX4RORJ9JALQN/i23yHa52uCrAEyY0D0F4OBBX/BNAIxMmACUiFwsACC+BTBwoFTAbW2d3T9A4WYFcy0AwHcD7dghlY02jc0mAC+95G/n2pqqUOhznTFDegRr89bugttiywTAyIQJQIkolgDoDGJAuAAU2gI4+WS59gsvSK9otQSUwYMzxwB0vuJyopZVfb0I0NatZS1OwVEBcKciNYwwTABKRK4uoEwjgroCAGQWgEJaAD16iJvpXe8C7rtPxOzZZ2W/unNeeilzDOC11/z1gwe7VqZ8cS0AoPsFglUAjj9eBCBqUEHDMAEoEbk0AwXixwA0L5C7BZCL62X/fhExIhEAfcv/7Gdlqe6cOXOkfFGVjisA5fK/t7SIEOu8y90tDuAKQHu7jOJqGGGYABQZDXx+/euyPWRIvMDn0KHy9hbWeicoABoIztUCyKUp5v79vohpxXnGGcD3v5+eb/BgqXSi3u5dF1C53rxbWuT5jhwpzWm7swAA5gYyoon5PmrkSyoln44Oadsf1xwfOlSOaW1Nr+yPHZPKPMwCCDYBBaItALczVxz275dzuGMjPf20CMzs2X6almv/fnEXBXntNWDaNOm3UC4BaG6WZ0Yk8xh3ZxcQIAIwblx0fiO5mAVQInIdQjqqN7C6XvK1ANQi0bf4uE0x9++XGb/CxkRaudLPp1ZCVBzgtdeA6dPFEiq3BQAAJ5xgFoCRXEwASkguw0hEjQjqjgOk5BID0MHuTj9dtuM2xXRdQJnINCBce7s0u5wwQSreShCAyZNFAPId4qMSqQQBqNbhtau13PliAlBCcvlxRY0IGiYA+kcPM/OjYgA6f3DcNrsyZigAABujSURBVPCtrekCEFVhZhKA7dulv0IlCIAK7OTJEq+48cbylKUYqADo76EcAlCt021Wa7nzxQSgQolyAbkCoO6cz31O0sICzGExAB3DH5Dx8OMQtACixMyNAQTRFkDjx4sAbN0qglBqgi6g7kZrqwS3hw+X7VLPClatLrW77ip3CUqPCUCFkk0ABg2KnrsgTABcC6C5WcYHAvIXgCjCYgBaHhWACRMkntDWVvqOYR0d8kY8dKiU60Mf8vd1l+khW1ulya6KcaksAH0hUVGtluep5f7MZ2S7WspdCEwAKpQ4FkAcwlxA6v4BgD17sp9DWyPlGwNQs1ore3UBAYVzA8X9s2ofBRUA9/mWa2iKQqMCUFsrLbFKKQDMwNSpsr1/f/TzrKRnrK309Pd97Fj3+B3EIZYAENFcItpERI1EtChkf28iWubtX0VEE730OUS0hohe8JbnO8es9M651vscV6ib6g707y9/4LgCEOWTD3MBuQIQxwLQkSXjCID2eN63Tz6nnebve+01cUv07194AYjru9XnqQI7eLA/W1t3QQUAELdgqWMAu3fLctWq6DyV5mvfvdt3W77xRnnLUkqyCgAR1QC4DcCFAKYBWEhE0wLZrgLQwswnArgFwM1e+h4AH2XmdwG4AsDPAsddyszTvc+uLtxHt0OHhI4TBAai31Z0IvcoCyCOAOgfIzjSaBg1NZJvxQqpfNaulXQi4Pbb/aEwxoyRshVCALQzWpwhr1UANAhMJB3C3v3urpejUnAFQDsUloq2Nv83+8QT4Xluv7105YnL5s3++quvlq8cpSaOBTALQCMzb2HmowDuBzA/kGc+gLu99QcBXEBExMzPMfM2L309gD5E1LsQBU8CQ4cCf/2rv714sf9WFfetlUjcQFEWQBwXkApAHAsAEHF65zuBd7wj/TrTpknvYUD6RXS1E5b6bv/xH2W7pia771YrJ7UAABGAsCa01Yrrriu1BeC+sAQFQL+vz39etivJ124CEM1YAK5R1OSlheZh5jYA+wAMD+T5OIDnmNlteHiX5/65gcjtY+pDRFcTUQMRNexW2zIhDB3qz/R1ww0ynMTvfy/bufx5grOCbdsmb4gDBuRmAcQVgEGDgIcfBl5+GfiXf5G0X/1KYgATJvj5Tjgh+i0xDqmU358BEGsjm+826AICRAB27sy/HJVGOV1A+hetqwOeeiq9lVcqBaxe7W9XUsxl82Z5gaipqd5WTPkQRwDCKubggAYZ8xDRyRC30D84+y/1XEPnep/Lwi7OzHcwcz0z19fV1cUobvdBK6mFC4E//UnW//3fZZnLnyc4L/D27fLGO2JE8SyAXbukErjpJnG33H67xBKCArBrV/6jVb76qlhE6r7Zti1zfiBaALRZbHegEgRg3jz5voNDjlSq0G7eDEyaJE2UzQJIpwnA8c72OADBv9rf8hBRTwCDATR72+MA/AbA5cz8N4Ofmd/0lq0Afg5xNRnwTeWHH5bt+++XcXcA4Mtf9vPEpU+f9ICcCsDw4cWxADQ+8fd/L37+a64BnntO0saP9/NNmSJL1/zOhRtukOV//ZcscxEAjQEAMp3lrl1dnzazUqgEAbjoIlkGLTwV2kmTSlemOGzeLL/HyZNNAIKsBjCFiCYRUS8ACwAsD+RZDgnyAsDFAB5jZiaiIQD+AOB6Zv7bT4GIehLRCG+9FsBHAASmFkkuUe37dX3JktwEoG/f9DexUlgAAPAPnr23YIG/b8IEX+CuvVbSpk7NzResx993n2zrLGX33pv92JYWESVtHQWIBdDeHj38djWhI7EGBaBUcwKoANTXA2PHigC436sKQL9+pSlPHJh9AZg0yVxAaXg+/WsBrACwEcADzLyeiG4konletjsBDCeiRgBfBKBNRa8FcCKAGwLNPXsDWEFE6wCsBfAmgB8V8sa6M7n6TLUvACA/9lwtAHeGqWzlIgKWLZPtCRNk+4EHZA4BTQsK3KBBIjK5CMDjj6ff04gREnjOho4E6jJypCwr1T2RC9pk1xWAjg4/vdioAAwfLsL8xBPpTT5VACrJ5bZjh8yZoAKwa1dy5lCI1Q+AmR9i5ncw8wnM/E0vbTEzL/fWDzPzJcx8IjPPYuYtXvo3mLm/09RzOjPvYuYDzDyDmU9l5pOZ+QvM3F6826xe3Pb9uQ5YphWyO2tXjx7yhpiPBZCtGWiY5bJkiVQAaoEcd1znt/39+4G77w6eLTMaHFfGjInvAurOAqBi7QoAUDo30O7d8nxra0UAgm3q3SFIjh0rTZmyoS5IdQEB3W+a0CisJ3CF41aUub75a4X8pS/J9pEj/qTsagHs25f9j7h/v5jscWczCytD1HAVS5YAs2YBt97qC1yc+9ywQTqULV4s2yYAQlCsyyEAdXXyHX7hC366tlpzY1G7KqTnjysAGptIihvIBCABaFPJ55/3+wCoAADZfd9xxwFyiWutaEWxebM/ImecXqIbNgAnneTnzUUA3AAwkF0ACtVMsRTNHSvBAlABcH9XKvx9+vj+/0pxA23eLBbL+PG+ACQlEGwCkABmee2rnnkmXQBGjJD1bHEAnQ84F8IquyhRuPhiCRgCwIUXxjv/hg3SsUwZM0YqlPYIR6KWJywGoC6LKAEoxLAFR46UZviDcgvAnj0iAIA812CP9R07/MmIKkkAJk8WC7euTixLswCMbsP48fKWu2qV/5bsWgDZ4gD5WABhRA0K1rs38Oabsv3II7LM1NFt3z7JHxSAjo5ot4JWvmEuICKJTYQJwF/+IssoYYnLV78qy2K3xim3AOze7b9YAMDEiX5z3wMHpHzTp8t2pbjctAUQIL+FSZPMAjC6EUTiBlILoE8fqRiyWQBa+RZKAKKu4cYItAK77rrojm4bN8oyKABAuBvouutk2d4u9xIUAKBzb2ANoL/3vbLds2d+wxboeb7zHdnu0aO4wx+UUwCY0y0AQARAhy3R56sd9wphAeTSciyMjg75PakAACYARjfk9NOBTZvkxz56tFRCagFECYC+NRdTAIIMGCDLP/4xOo+2AMomAFr5futbsq1BbO1U5xImAMzA+d74tddfn9/QxqmUWCw6J/Qvf1nc4Q+CAqAumF//ujjXc9m7V4Z+cAVg0iRpUeNOQjRhgpSrEAIQ160WlW/bNimzKwA6TWihrLVKGOoiChOAhKBxgEcf9Qc+y+QC+sUv/PVSCYDGCN77Xuk5HOWa2rBB3EYTJ/ppUQLQ1ORv68iol17a+ZxR4wFpqykdgymMbJXQM8/4vYy1SW6xCApAz54iqitXFve6QPo4QMrEieL62bPHf76jRsmnqwLg9gXJhDugYpCXX5Zl0AI4cAD413/tnD+fyjzT76Pc4mACkBBmzpS34SNHfAHo1096xLoWgL41f+pTsk0kb3BaERYT/TPcdJO8fT32WHi+DRuk01dNjZ82cqSUNegCWr/eX1cLIMoFFByXaN8+Od+AAdKPQWc0c9ExmjLxxBNStiFDSiMAPXqk93QOtnoqFlECAMhvSCt8FYB8YwD6Gz3vPNmOihdpvnPP7ZxP911wgeybM8ffpy2BdNwtl1wC+a+/Dpx5ZuY85Z4XwQQgIegQzUD6NIzBzmBLlgBnneVvd3RIxfn+95emnIAMIzB4cLQbaOPGdPcPIGUcObKzALzoDDCivTs/+tHOFcbIkTJNpusr37RJltrXwLUCtAKZM0e2tXLRmIHLk08Cp5wCfOxjwJo1xQ0E6zhAen9E/vdd7OGXwwRAK1MVACLZ3xULIJVKn1MgamDEVMofgwqQ37LmUxffFVd0Pod2BnM5dMi3MuOWccIE390Y9uzVWisnJgAJQvsDuEPyBoeDWLhQKiwdX2fNGvGRlioGAEhlfv75IgDByvLAAalMggIAhPcFWL9eWvhkmztZ+wK4lZIGm+fNk7kNggLwiU/4b9rDhkl+bTWktLdLJXD22cB73iNi67qlCo07EJxWcjpo3ttvFzf+EMcCqKvzxborLiC3YneHnA7iWlyNjZnPA8iz0WFLAL/i7tfPb0IdR0hTKeCzn/X7PHz4w366CrP+p8o5L4IJQIJwx85Xhg/3LYC2NhnHZ+pU4J57JO1Xv5JlKQUAEIvjtdfSe5OmUr4rKkoA3MluABGAk0/Ofr2wzmAvvSSV1eTJwEc+Ii6p//t/Zd+VV8oYR4u8Ua9qa4G5czufd8MGiaGcdRYwY4akFdMN5AqAUl8vy+efL951gXABGDRIxPHVV6XC1+c8apQ8F3eeilx49ll/djn3hSYsn7oKgy7FI0fk+znnHD9NRVNfgPRlwXUHxR2K/ZlnfPfTH/7Q+Rr6u1y3rnzzIpgAJIRUyp+JCfDfOnbs8C0ArfRvukkqvalTgQcflLRSC4C6Vr73PT9t6dLwFkBK0AJg7iwAUZ3RwgRAmwfW1ooAHD0qz2bjRhm7aPx4GZ579mw5TmME7hvdk09K2llnSQeoHj3EqlIK/acPEwAVHve6xWDPHomXuIMPAmIFqAUwapSk6TKfOMCxY1JpXnqpPM8VK9L3u890zRp59mPHAn/+c3q+DRvkpUdnlHPRl6WjR2XpDmERZwDFAwfkt3fwYHq6/jYWLfLjU/obKQcmAAlB3zq0Q5O+xcyeLT5iIuCqq2Tfxz4m24MH+2ZzqQXgxBP9yWNmzJAgNiCzogH+pPIuo0dLIFfHNnr9dXF7uAIQVeFGWQAaNznnHL/VlIrPt78tJv7KlfIs9W3P9TU/+aTkmTxZltOmpVsAhQ4ChgnAmDFyfw0Nhb1WkGAnMEUFYOfOzgKQjxvopZfk7f3975ffhSsAhw/7z7StTayeGTOA971PBMB1Kep81doxzUUFYN06Wa5a5ccAMlkcynPPyX/tK1+Ra+pgh88+6//vFBMAo2T0CHzjI0bIn8mdL0DFQX3HQO5DQXSFVErKqW/Uzz7rV146cFevXp39pmPGSLm1Etc3rDguoOHDxVWgxx47JvMVn3SSXKNXr85vfp/8ZHoZPvtZWbrNE594Qt4CdcLT97zHF4CguyoumayGMAEgEjdQHAugKx2rdBygINoXwLUAwmIucVG//WmnAR/8oLhampvlWatIAxLEP3RInvn558vLgTuK7Nq1MuxD2MuECsCqVfI9vf46cPXV8izjCIDm0RcXbUShrcaefFJ+b3PmmAAYJcZ1gwwfLpXmf/5nerNKQN5StOlkKS2AbBPiuGlBAQB8N1AuAtCjh1ReKgCNjfIG+c53hpcnrAwXXyxCceedsv3cc50nvZ8xQyoUIr+8wSBgtko4zGrQY1pbw8exmTFDXFfZxrnvSseqKAGYOFEq4iNH0mMAQH4C8OyzEnyfOlUEoKND7u+cc3yXC5G0vAJ8CwDwZ9QDRABOPbXz7x5IHz5F3T9z5sjv4ZlnspfxmWeA44/373PMGHk22rLtySelR/QHPiC/tXKNjGoCkEDcCkZN9p/9TIKYrjgMHOg3CS21CygftEL9j/+Q5fr14haK2w5+5Ejgf/9X1jXYfNJJ8a/frx/wmc9Ib9/6ennzVLSSV7cDAIwbJ8sLLkgXkkyVsI6ZpASPaW313RYuM2ZIReleP8iLEXPyBYck18llVAh1fyYBULRCrKuT55FPDOC556TyrKmRDo6DB4uFMXy4P+zH008D//zPvlBMnCiWiI41xSzPIsz9A/jDp6gA1NaKxTFrllTu2Zryrl7tv/0rn/qUWIdvvy3nPOssv5/AU0/l/hwKgQlAwlGT+cgRaRMdfPvUli2l6kwUJGxCnKhArgqAzkgWtwWQMnKk72LSJqBTp4aXJ6oMV10lb7tr1kjFpK41tRZuvdVvGqhtxB99VIQnlfKvq+P6K9p0UEVDBWXpUj+4f9JJ/pzHQbQlUJgbSM+tzR9di6StTa5x6JA/uY+6mHRco6VL5d4yuYAUFYDaWvntZbMAgr/Hjg4RABXXnj39EWT/+7/9Vlp33SX3On26/4avVkB7u7RK2r8/WgAAEYCXXxbRePe7RUxmzpS3dXeim2AZ33pLLL9ZgVnO58yRGMXtt4slpi3DamujBaDoLYOYuWo+M2bMYKOwNDRo1cR86JCfvmSJn+5+liwpV0mz09bGXFMj5WxvZ+7Zk/kLX4h//OWXy7E7djBfdhnzwIG5l6Gjg/nd75bzrFwpaYAso55p//7MEyaE75s92z/3Lbek75s8OfyYqO9r1CjmU0/1t3Xfww9L3mnTZDlxInNLC/OXvsQ8c6Z/rsGDZXn66bLs04d5yBBZb22V5c03d34mug9gfvFFP/2UU5gvuqhzfrfM+uyUzZsl7Uc/in6exx3HPGgQc20t8zXXROcDmFetiv4u//QnP98110jaM8/I9i9/Kdv793cu4yOPSNqjj6an798vv8njjpP9W7dK+hlnMJ97bngZgufOFwANHFKnxqp4AcwFsAlAI4BFIft7A1jm7V8FYKKz73ovfROAD8Y9Z9jHBKDwbN3q/8ijKNSPsJhE/ck/+tH8j831vqPO41biinvu737Xzzt1qr/+pS/5+XbuZO7Vi3nu3OyVfVS5P/zh9H2AiF5trazv2iXLnj2ZJ03KLi5hn3nzwq89YoTs37PHT3v/+5nHjk1/flqup59m/tznZL2tzd+3bJmkrVkT/TwffdQvz09+4qd3dPjpp54qywMHwsvLzLx3LzOR5LvnHkk7fFi+h7POEoFXAWxq8st4442Stndv53Oee67sGzBAysPM/MUviph+7Wv+c9i0ifnMMyXv4cNdf/HKWwAA1AB4BcBkAL0APA9gWiDP/wFwu7e+AMAyb32al783gEneeWrinDPsYwJQWOK+5VeDACjt7en38uSTuR0PMNfV5ScAwfPE2R/1Hbhv3itXMl95paxv3Oh/P3v2+OcJVuxh6LU+/vHM1sOcOf76mjXh59YyuG/3APPvfhd+bb2f9nY/7dOflrSWFuYtW2T9a1+LLtfixcxf/rJfKUY97/Z2sWIA5rVrO+dzRTQbJ50k+V5+2U+bNSu6jJdc4otLGCoO7v4HH0xPyybw+dAVATgTwApn+3oA1wfyrABwprfeE8AeABTMq/ninDPsYwJQPDL9GSrZ7ROkq66rQv35slUuwfMdPuwfM3t2dDmiruOeL3juTBZO8NzZnl9UGerrZRnlUlmwoPOxX/lKvHL16ydLtVTCyqDly1b+qGcb9f2qFaJv68ziDgKYzz6b+a23ZD2TxeSe+6mnOt/Dtm1+Wq9esjz9dObXX0+//w0bwssYh64IwMUAfuxsXwbg+4E8LwIY52y/AmAEgO8D+LSTfqd3vqzndPZdDaABQMP48ePzfwJGRuK8DVUL2VwhcY7N9/iw88QlqnLNVKl0RZii1oNp+YhLtgo522fJknjHRt2/unuiyLY/33JnEutCnDPTPWeiKwJwSUhl/b1AnvUhAjAcwG0hAvDxOOcM+5gFUDyq6S0/Ll0VtVKLYth3kK2SzpWo82W7dq7njrs/rDxh5crnOeRTnrj5ulrGTOfMdu58iBKAOM1AmwAc72yPAxCceO9veYioJ4DBAJozHBvnnEYJKffEFMUgqqlmqY7PlbDvoNBlCGtWW6prxyVbufI5Tz7741LMZ1f2ZqAQn/4WSBBXA7YnB/Jcg/Qg8APe+slIDwJvgQSAs54z7GMWgJFkKt1Ky1a+sP2Z3Ev55CsG2cqdKS2fc3b13GEgwgIg2ZcZIvoQgO96lfdPmPmbRHSjd9LlRNQHwM8AnAZ581/AzFu8Y78K4DMA2gD8MzM/HHXObOWor6/nhmKPaGUYhtHNIKI1zFzfKT2OAFQKJgCGYRi5EyUANhSEYRhGQjEBMAzDSCgmAIZhGAnFBMAwDCOhVFUQmIh2A3gtz8NHQIao6A7YvVQu3el+7F4qk3zuZQIzdxqsu6oEoCsQUUNYFLwasXupXLrT/di9VCaFvBdzARmGYSQUEwDDMIyEkiQBuKPcBSggdi+VS3e6H7uXyqRg95KYGIBhGIaRTpIsAMMwDMPBBMAwDCOhJEIAiGguEW0iokYiWlTu8uQCER1PRH8moo1EtJ6IvuClDyOiPxLRZm85tNxljQsR1RDRc0T0e297EhGt8u5lGRH1KncZ40BEQ4joQSJ6yft+zqzW74WI/sX7fb1IRL8goj7V8r0Q0U+IaBcRveikhX4PJNzq1QXriOg95St5OBH3823vd7aOiH5DREOcfdd797OJiD6Yy7W6vQAQUQ1kZrILIZPULySiaeUtVU60AfgSM58E4AwA13jlXwTgUWaeAuBRb7ta+AKAjc72zQBu8e6lBcBVZSlV7vwngEeY+Z0A3g25p6r7XohoLIB/AlDPzKdAhmhfgOr5Xn4KYG4gLep7uBDAFO9zNYAflKiMufBTdL6fPwI4hZlPBfAyZB51eHXBAsjcK3MB/JdX58Wi2wsAgFkAGpl5CzMfBXA/gPllLlNsmHk7Mz/rrbdCKpmxkHu428t2N4CLylPC3CCicQA+DODH3jYBOB/Ag16WqrgXIhoE4DzINKdg5qPMvBdV+r1AJmnq683o1w/AdlTJ98LM/wuZh8Ql6nuYD+Aeb56UpwEMIaLRpSlpPMLuh5n/h5nbvM2nIbMoAnI/9zPzEWZ+FUAjpM6LRRIEYCyAN5ztJi+t6iCiiZBJd1YBGMnM2wERCQDHla9kOfFdAP8KoMPbHg5gr/PjrpbvZzKA3QDu8txZPyai/qjC74WZ3wTw7wBeh1T8+wCsQXV+L0rU99Ad6oPPAHjYW+/S/SRBACgkreravhLRAAC/gsyqtr/c5ckHIvoIgF3MvMZNDslaDd9PTwDvAfADZj4NwAFUgbsnDM8/Ph8yResYAP0hrpIg1fC9ZKNaf28A/jbDYhuA+zQpJFvs+0mCAFT9BPREVAup/O9j5l97yTvVdPWWu8pVvhw4G8A8ItoKccWdD7EIhniuB6B6vp8mAE3MvMrbfhAiCNX4vbwfwKvMvJuZjwH4NYCzUJ3fixL1PVRtfUBEVwD4CIBL2e/A1aX7SYIArAYwxWvR0AsSMFle5jLFxvOR3wlgIzP/h7NrOYArvPUrAPy21GXLFWa+npnHMfNEyPfwGDNfCuDPAC72slXLvewA8AYRTfWSLgCwAVX4vUBcP2cQUT/v96b3UnXfi0PU97AcwOVea6AzAOxTV1ElQ0RzAVwHYB4zH3R2LQewgIh6E9EkSHD7mdgnDpspvrt9AHwIEjl/BcBXy12eHMt+DsSkWwdgrff5EMR3/iiAzd5yWLnLmuN9vRfA7731yd6PthHALwH0Lnf5Yt7DdAAN3nfz3wCGVuv3AmApgJcAvAjgZwB6V8v3AuAXkNjFMcgb8VVR3wPEZXKbVxe8AGn5VPZ7iHE/jRBfv9YBtzv5v+rdzyYAF+ZyLRsKwjAMI6EkwQVkGIZhhGACYBiGkVBMAAzDMBKKCYBhGEZCMQEwDMNIKCYAhmEYCcUEwDAMI6H8f8t1CqkIpHdJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025684879097692223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#visualzing graphs\n",
    "# writer=SummaryWriter('runs/experiment_1')\n",
    "# dataiter=iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(images.shape)\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# #writer.add_image('images', grid, 0)\n",
    "\n",
    "# #images = images.reshape(-1, 28*28).to(device)\n",
    "# dummy_input = torch.zeros(1, 28*28),\n",
    "# writer.add_graph(model, dummy_input)\n",
    "# writer.close()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "\n",
    "print('elapsed: ', time.time()-start)\n",
    "plt.plot(losses, '-b+')\n",
    "plt.show()\n",
    "print(np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n",
      "sample size: torch.Size([100, 784])\n",
      "relu Size: torch.Size([1000, 100])\n",
      "Average Active Neurons = 384.63\n",
      "sparsity 0.61537\n",
      "Accuracy of the network on the 10000 test images: 98.11 %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99.1 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #check dead neurons\n",
    "# dataiter=iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# images = images.reshape(-1, 28*28).to(device)\n",
    "# print(torch.max(images[0]))#pixels are normalized\n",
    "\n",
    "# print(images.shape)\n",
    "# A1 = images[:100]\n",
    "# print(\"sample size:\", A1.shape)\n",
    "# output, output_relu = model(A1)\n",
    "\n",
    "# output_relu = output_relu.T.detach()\n",
    "# print(\"relu Size:\", output_relu.shape)# interesting, data size is in second dimension. \n",
    "# # plt.plot(output_relu.numpy(), '-b+')\n",
    "# # plt.show()\n",
    "# print('Average Active Neurons =', np.count_nonzero(output_relu)/A1.shape[0])\n",
    "# print('sparsity', 1- np.count_nonzero(output_relu)/ (output_relu.shape[0] * output_relu.shape[1]))\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "labels_wrong = []\n",
    "pred_wrong = []\n",
    "img_wrong = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, labels in test_loader:\n",
    "#         print(img.shape)\n",
    "        #images = img.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs= model(img)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        wrong_preds = (predicted != labels).numpy()\n",
    "        wrong_index = []\n",
    "        for (i, wrong) in enumerate(wrong_preds):\n",
    "            if wrong:\n",
    "                wrong_index.append(i) \n",
    "        if len(wrong_index) > 0:\n",
    "            img_reshaped = img[wrong_index].numpy()[:,0,:,:]\n",
    "            for img_w in range(img_reshaped.shape[0]):\n",
    "                img_wrong.append(img_reshaped[img_w])\n",
    "            labels_wrong  += (labels[wrong_index].numpy().tolist())\n",
    "            pred_wrong += (predicted[wrong_index].numpy().tolist())\n",
    "#     print(img_wrong)\n",
    "#     print('img_wrong.shape', img_wrong[0].shape)\n",
    "#     print('lables_wrong =', labels_wrong)\n",
    "#     print('predictions wrong are:', pred_wrong)\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "#show wrong images:\n",
    "# print(len(img_wrong), ', ', len(labels_wrong), ', ', len(pred_wrong))\n",
    "# for i in range(len(img_wrong)):\n",
    "#     plt.imshow(img_wrong[i])\n",
    "#     print('labels_wrong[i]:', labels_wrong[i])\n",
    "#     print('pred_wrong[i]', pred_wrong[i])\n",
    "#     plt.pause(1)\n",
    "\n",
    "# Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Active Neurons = 37.462\n",
      "layer 1:\n",
      "[Parameter containing:\n",
      "tensor([[ 0.0130, -0.0188, -0.0024,  ..., -0.0205, -0.0091, -0.0043],\n",
      "        [ 0.0033, -0.0016,  0.0280,  ..., -0.0147, -0.0031,  0.0006],\n",
      "        [ 0.0079,  0.0102,  0.0261,  ..., -0.0042, -0.0020, -0.0068],\n",
      "        ...,\n",
      "        [-0.0171,  0.0092,  0.0084,  ...,  0.0206,  0.0248,  0.0227],\n",
      "        [ 0.0295,  0.0247,  0.0058,  ..., -0.0149,  0.0173, -0.0035],\n",
      "        [ 0.0348,  0.0101,  0.0070,  ...,  0.0008,  0.0263, -0.0051]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 4.5606e-02, -8.7214e-03,  6.5915e-02, -2.7034e-02,  4.6711e-02,\n",
      "         3.8341e-02,  1.8096e-02,  1.7200e-02,  3.2345e-02, -6.4435e-02,\n",
      "        -1.9535e-02,  3.6509e-02,  1.8641e-02,  2.1812e-02, -6.9894e-02,\n",
      "        -3.1382e-02, -4.6306e-02,  1.7369e-01, -1.7433e-02,  3.5536e-02,\n",
      "        -1.5135e-02, -4.6255e-02, -1.6067e-02,  3.7119e-02, -5.2715e-03,\n",
      "         1.9340e-02, -5.4811e-02, -3.1189e-02,  1.0628e-01, -5.9413e-02,\n",
      "         3.2564e-02, -5.6688e-03,  5.3045e-02,  9.0088e-03, -7.0852e-03,\n",
      "        -7.8958e-04,  1.2716e-03, -5.2556e-03, -7.4646e-03, -1.6943e-02,\n",
      "         6.9714e-02,  1.4044e-02, -6.0080e-02,  2.0178e-02, -2.2394e-02,\n",
      "         1.7625e-02, -4.6556e-02,  1.7880e-02,  1.1039e-02,  2.0918e-02,\n",
      "        -2.5954e-02, -7.9955e-03, -8.4244e-02,  2.9089e-02,  6.5932e-02,\n",
      "         5.5733e-02, -6.4621e-02,  7.3909e-02, -3.1039e-02, -3.1484e-02,\n",
      "        -8.1424e-03, -4.3214e-02, -7.0470e-03,  2.3588e-02,  3.4756e-02,\n",
      "         4.2056e-04,  8.3391e-02,  1.3967e-02,  7.1620e-02, -3.3731e-02,\n",
      "        -3.8899e-02, -1.4415e-03,  2.4781e-02,  7.5222e-02, -1.3309e-02,\n",
      "         2.3759e-02,  2.4987e-02,  3.7883e-02,  7.0833e-02,  6.4792e-02,\n",
      "         4.2034e-02,  2.9059e-02,  5.2292e-02,  7.7332e-02, -6.3001e-03,\n",
      "        -1.7858e-02, -1.2082e-02,  5.4612e-02, -3.9634e-02, -5.9022e-02,\n",
      "        -2.7410e-02, -9.6043e-03, -3.7962e-02,  9.2622e-03,  3.4352e-02,\n",
      "        -7.1566e-04,  3.5429e-02,  6.7719e-02,  1.2770e-02,  2.0616e-02,\n",
      "         5.4464e-02,  1.2919e-01, -1.2640e-02,  6.5282e-03,  4.3497e-02,\n",
      "         5.1912e-02,  1.6006e-02,  4.9353e-02,  1.1153e-02, -3.4716e-02,\n",
      "        -1.0647e-02,  7.6781e-03,  6.8343e-02, -3.0489e-02,  1.1503e-02,\n",
      "        -2.4442e-02,  2.4542e-02, -1.6423e-03, -1.2030e-02, -8.7269e-03,\n",
      "         8.9073e-03,  1.0987e-02, -5.1227e-02,  2.8335e-02,  1.0400e-02,\n",
      "        -2.9407e-02, -5.7380e-02,  1.6942e-02,  3.2469e-02,  2.6801e-02,\n",
      "        -3.8349e-02,  7.1896e-02, -1.2283e-03, -1.8689e-02, -1.9519e-02,\n",
      "         6.6803e-02, -5.7335e-02,  3.5204e-02,  7.2868e-04,  2.7767e-02,\n",
      "         3.1765e-02, -1.5523e-02, -4.2467e-02, -2.1506e-02,  4.4315e-02,\n",
      "         2.4518e-02,  1.3377e-03,  4.4967e-02, -3.4568e-02, -3.8758e-02,\n",
      "         4.2841e-02, -3.8058e-02,  1.0172e-02,  2.1137e-02, -4.4640e-03,\n",
      "         3.2503e-02,  1.0521e-02, -1.3269e-02, -1.4388e-02, -3.5900e-02,\n",
      "         4.0401e-02, -3.3647e-02,  4.6135e-02, -1.2176e-03,  6.5839e-03,\n",
      "         4.2197e-02,  3.4256e-02,  1.1286e-01,  6.9851e-02, -9.5754e-03,\n",
      "        -3.4230e-02,  5.3626e-02,  7.5959e-02,  4.8225e-02,  9.9445e-02,\n",
      "         8.0105e-03,  6.6573e-03, -1.0963e-02, -2.2752e-03,  4.7086e-02,\n",
      "         1.3182e-02,  6.3068e-02, -1.7314e-02, -3.5524e-02, -8.9618e-02,\n",
      "        -6.4506e-02, -2.1929e-02, -2.6995e-02, -5.2766e-05,  4.4487e-02,\n",
      "         8.8833e-03,  6.9965e-02,  3.2153e-03, -2.0945e-02, -9.5496e-03,\n",
      "        -1.8518e-03,  1.0156e-01, -3.9285e-02,  1.6619e-02, -8.6584e-02,\n",
      "        -4.8955e-02,  5.5615e-02,  3.2547e-02, -4.8525e-02, -2.6588e-02,\n",
      "        -2.6077e-02,  5.6051e-03,  1.6212e-02, -2.1915e-02,  1.9396e-03,\n",
      "         2.0467e-02, -2.9198e-02,  8.8569e-02, -1.6358e-04,  2.2769e-03,\n",
      "        -4.4054e-02,  5.1759e-02,  9.0957e-02,  2.3596e-02, -4.3008e-03,\n",
      "        -3.2703e-02, -5.7063e-03,  3.1302e-02, -6.8360e-02,  3.1619e-02,\n",
      "         9.3879e-02,  2.8976e-02,  2.7682e-03,  5.3162e-02,  6.0703e-03,\n",
      "         4.5386e-02,  9.5195e-03, -5.3459e-02,  7.1768e-02, -2.8763e-02,\n",
      "         7.1860e-03, -5.4795e-02, -8.6467e-02, -1.9357e-04,  3.5820e-02,\n",
      "         8.3895e-02, -1.3192e-02,  4.5015e-02,  1.0655e-02, -2.8369e-02,\n",
      "         6.0337e-02, -1.9112e-02, -3.1754e-02, -2.9697e-02,  2.6265e-02,\n",
      "        -5.8131e-03,  7.1158e-03, -1.9470e-02,  3.9133e-02,  2.9827e-02,\n",
      "         9.8042e-03, -2.4295e-02,  7.0669e-02, -1.6955e-02,  1.3191e-02,\n",
      "         6.6144e-02,  1.3811e-03,  2.1016e-02, -5.5616e-02,  3.5124e-02,\n",
      "         7.7630e-02,  1.3055e-01,  3.0906e-03, -2.6614e-02, -5.3930e-03,\n",
      "         1.7808e-02,  1.2209e-01,  2.8028e-02,  3.9663e-02, -1.8637e-02,\n",
      "         2.0539e-02, -2.3793e-03,  4.5559e-02, -3.2710e-02,  6.0751e-02,\n",
      "         7.6649e-03,  9.7795e-03, -2.7452e-02,  2.5875e-02,  3.0546e-02,\n",
      "        -4.7749e-02,  1.2965e-01, -3.1853e-02, -1.3850e-02, -1.1841e-02,\n",
      "         2.9938e-02,  1.0982e-02, -5.5761e-02,  2.4140e-02,  6.6126e-02,\n",
      "        -2.8823e-02, -2.0759e-02, -2.7462e-02,  1.2926e-02,  4.4329e-02,\n",
      "        -6.1533e-02,  1.5342e-02, -9.2040e-03, -3.3715e-03,  4.2618e-02,\n",
      "         7.5908e-02, -1.7509e-02,  5.1014e-04,  1.5183e-02,  1.0436e-02,\n",
      "         4.1071e-02,  5.3767e-03,  2.3180e-02,  3.8262e-02, -2.9802e-02,\n",
      "         1.5526e-02,  4.2126e-02,  7.4912e-02,  1.5979e-02,  7.9306e-02,\n",
      "        -2.9945e-02, -3.7039e-02,  3.2260e-02,  1.2299e-02,  5.6954e-02,\n",
      "        -6.4975e-02,  8.9161e-02,  2.6947e-02,  4.4164e-02,  1.2197e-02,\n",
      "         1.4109e-02, -2.8430e-03, -2.0751e-02, -5.5645e-02,  1.9415e-03,\n",
      "         5.4756e-02, -1.9423e-02, -3.1441e-03, -2.3445e-03,  2.3694e-02,\n",
      "         2.5649e-02, -2.5775e-02,  5.4326e-02, -2.0529e-02,  8.6809e-03,\n",
      "         1.1820e-01, -6.5228e-02,  6.6104e-02,  4.8296e-02, -7.5664e-02,\n",
      "         6.6189e-02,  1.3977e-02,  4.8213e-02, -2.6428e-02, -6.2585e-02,\n",
      "        -2.1348e-02, -4.6005e-02, -5.5252e-02,  7.4930e-02,  7.1291e-02,\n",
      "         1.9897e-02,  2.0231e-02,  4.0584e-02, -1.2299e-02,  8.1589e-02,\n",
      "         1.5981e-02,  1.7969e-02, -8.0408e-03, -2.8926e-03,  3.6392e-03,\n",
      "         5.2355e-02,  4.2852e-02, -6.6345e-02,  4.3546e-02,  1.6746e-02,\n",
      "         2.4928e-03,  7.5091e-02,  5.2476e-02,  2.2694e-02,  6.3391e-02,\n",
      "         1.5392e-02,  7.1546e-02, -2.5151e-02, -1.5101e-02,  4.6466e-02,\n",
      "        -2.2622e-02,  2.4787e-02, -1.8238e-03,  3.7768e-03, -4.2260e-02,\n",
      "         3.0793e-02,  1.1419e-01,  2.0803e-03,  1.8669e-02,  4.9435e-02,\n",
      "         2.2347e-02, -5.6051e-02, -2.6536e-02,  1.0197e-01,  3.4533e-02,\n",
      "        -3.1389e-02, -7.6450e-02,  2.6703e-03, -5.6084e-02, -4.4734e-03,\n",
      "        -3.5498e-02,  7.5444e-02,  3.4847e-02,  1.9533e-02,  9.6805e-03,\n",
      "         9.0696e-02, -3.4148e-02, -1.1498e-02,  2.5503e-02,  2.4095e-04,\n",
      "         5.3353e-02, -2.8139e-02,  5.4743e-02,  1.6494e-02,  9.2381e-02,\n",
      "        -8.4002e-02,  2.6053e-02, -1.4349e-02, -1.5922e-02,  1.3694e-02,\n",
      "         2.1730e-03,  7.7297e-02, -4.9760e-02,  8.2016e-03, -4.7823e-02,\n",
      "         3.2043e-02,  6.8214e-03,  8.6583e-02, -3.8421e-02,  2.4499e-02,\n",
      "        -3.2574e-03,  3.8076e-03, -4.3707e-02, -1.0516e-02, -1.9288e-02,\n",
      "         1.7301e-02,  4.7159e-02, -6.0897e-04,  9.6922e-03, -1.4971e-02,\n",
      "         9.3970e-02, -7.6754e-03,  2.2072e-02, -2.2016e-02, -1.2804e-02,\n",
      "        -1.5691e-02,  7.4864e-02, -7.4242e-02, -5.9246e-02, -1.0907e-02,\n",
      "         4.3244e-02,  2.7741e-02,  3.3394e-02, -8.9748e-02, -8.7571e-02,\n",
      "         3.5101e-02, -8.4394e-02, -5.0802e-02, -3.6395e-02,  6.6747e-02,\n",
      "         3.6684e-02, -1.7591e-02, -2.9969e-02, -1.2622e-02, -3.5432e-02,\n",
      "        -3.3104e-02,  8.8118e-02,  8.0812e-02, -3.4994e-02,  3.1103e-02,\n",
      "        -4.7850e-02, -9.4733e-03,  3.7925e-02,  1.7221e-02,  3.7125e-02,\n",
      "        -1.2528e-02,  1.5633e-02, -2.6299e-02,  5.7935e-02, -5.4553e-03,\n",
      "        -1.0559e-02,  7.9758e-02,  3.0871e-02, -3.5175e-02,  4.8422e-03,\n",
      "         4.4088e-02, -2.0866e-02,  4.3121e-02, -4.2904e-02, -5.0624e-02,\n",
      "         1.9874e-02, -2.1427e-02,  7.3820e-02,  1.8757e-02, -5.2640e-04,\n",
      "        -3.6559e-02,  3.1213e-02, -2.1253e-02, -1.5326e-02, -3.1099e-02,\n",
      "        -3.6040e-02,  1.5640e-01, -5.4918e-02,  9.3257e-02,  1.2407e-03,\n",
      "        -2.3634e-03, -1.9375e-03,  2.2169e-02,  3.7682e-02,  7.1853e-03,\n",
      "        -8.7566e-02,  2.0677e-03, -5.4930e-02, -4.3668e-04, -1.5679e-02,\n",
      "         3.2709e-02,  4.0179e-02,  2.8571e-02, -3.1078e-02, -1.9311e-02,\n",
      "        -6.0696e-02,  4.6141e-02, -5.3671e-02,  4.6193e-02,  6.9413e-02,\n",
      "        -2.9670e-02,  2.8304e-02, -4.6503e-02,  4.2162e-02,  2.5417e-02,\n",
      "         5.4381e-02,  1.2850e-02, -4.4397e-02, -2.7332e-02,  2.7781e-02,\n",
      "         4.9837e-02, -1.5481e-03,  1.7046e-02, -2.8270e-02, -2.0159e-02,\n",
      "         1.2873e-02,  1.1300e-02,  3.4400e-02,  3.6118e-02,  3.6674e-03,\n",
      "        -7.8840e-02,  2.1909e-02,  3.0429e-02, -1.1189e-02,  2.7330e-02,\n",
      "         4.4138e-02,  1.4178e-02,  1.3413e-02,  4.4438e-02,  1.9030e-02,\n",
      "        -2.2350e-02,  4.8119e-02,  9.8161e-02,  2.1822e-02,  6.9992e-02,\n",
      "        -2.6718e-02, -2.0800e-02, -3.9225e-02, -1.9216e-02,  4.8080e-02,\n",
      "        -3.0780e-02,  1.0501e-01, -9.4270e-03,  2.4556e-02, -3.0274e-02,\n",
      "         3.2946e-02,  1.1534e-02,  5.5002e-02, -4.3895e-03, -4.8096e-02,\n",
      "        -2.0898e-02, -3.9661e-02, -1.4687e-02,  1.7820e-02,  3.6583e-02,\n",
      "        -4.3285e-02, -1.6193e-02, -2.0502e-02,  1.8113e-02,  2.3586e-02,\n",
      "         9.7242e-03,  6.1828e-02,  3.4645e-02, -7.3539e-04,  2.3035e-02,\n",
      "         7.2627e-02,  1.0163e-01,  2.0383e-02,  1.6001e-03,  1.7002e-03,\n",
      "         1.5504e-02, -1.5760e-02,  6.8470e-02, -5.4688e-03, -1.5710e-02,\n",
      "        -1.4646e-02,  8.4554e-02,  4.0927e-02,  6.4976e-02, -3.0051e-02,\n",
      "         6.3965e-03,  8.8718e-02,  4.1012e-02, -7.0229e-03,  8.1015e-02,\n",
      "         6.0137e-02, -6.4158e-03,  7.8168e-02,  4.1779e-02,  6.1527e-02,\n",
      "         3.6467e-02, -5.6414e-03,  3.5815e-02, -6.5663e-02,  1.2876e-02,\n",
      "         4.4593e-02,  2.9341e-03,  2.5815e-03, -7.0580e-02,  6.8308e-02,\n",
      "         6.7009e-02,  3.9558e-02, -2.2790e-02, -3.8541e-02, -3.8024e-02,\n",
      "         1.0262e-02,  5.8310e-02, -3.2640e-02,  3.9890e-02, -1.1184e-02,\n",
      "         5.7646e-02,  7.3860e-02,  7.4846e-03, -4.4581e-02,  1.4595e-02,\n",
      "        -2.2603e-02,  6.4942e-03,  1.9235e-02,  2.9192e-02, -2.3725e-02,\n",
      "        -5.2156e-02, -2.5937e-02, -3.8228e-03, -1.0126e-02,  1.0411e-01,\n",
      "         3.2508e-02,  4.7746e-03, -4.8085e-02, -1.2120e-02,  3.7607e-02,\n",
      "        -1.9376e-02,  4.6045e-02, -4.2208e-02, -3.5305e-02, -1.7497e-02,\n",
      "        -5.4140e-02,  8.7064e-03,  3.8567e-02, -2.7885e-02, -1.5630e-02,\n",
      "         6.4612e-03, -1.1284e-02,  2.0893e-03, -3.9382e-02,  2.5403e-02,\n",
      "        -5.9822e-03, -4.0724e-02,  2.7388e-02,  5.6240e-02, -3.8381e-02,\n",
      "         1.8186e-02,  2.6581e-02,  3.3658e-02,  5.7343e-02, -9.0837e-03,\n",
      "         1.0086e-02,  6.7313e-02,  8.8384e-02, -1.4206e-02,  1.2002e-02,\n",
      "         2.5178e-02,  5.1186e-02,  2.2594e-02,  1.1135e-02, -1.0082e-02,\n",
      "         3.3453e-02,  7.9607e-02,  1.8668e-02,  8.9566e-03, -3.8560e-02,\n",
      "         2.3692e-02,  4.4401e-03,  4.5828e-03,  7.6601e-02, -3.1172e-02,\n",
      "        -1.1813e-02,  1.5339e-02,  2.4051e-02,  4.4775e-02, -1.2062e-02,\n",
      "         3.8125e-02,  5.2197e-02, -3.4780e-02,  5.4848e-02,  9.8166e-02,\n",
      "        -3.8014e-02,  6.5414e-02, -1.9945e-02,  5.2936e-02, -3.4294e-02,\n",
      "        -7.4967e-02,  1.0057e-01, -2.8685e-02,  7.7017e-02, -2.7642e-02,\n",
      "         2.0899e-02,  3.7893e-02,  1.3316e-01, -4.7610e-02,  2.3597e-02,\n",
      "        -7.3428e-02, -3.3470e-02, -3.5136e-02, -1.1368e-02,  1.8964e-02,\n",
      "         1.4255e-02,  3.1018e-02,  9.2880e-02,  1.9230e-02,  1.0160e-02,\n",
      "        -5.1039e-02,  3.0448e-02, -9.2597e-03,  6.4623e-02, -7.9203e-04,\n",
      "         6.7760e-02, -6.6467e-02,  1.1413e-01,  6.3195e-03,  2.3119e-02,\n",
      "        -3.6426e-02,  6.7792e-02, -1.2845e-02,  9.4600e-02, -3.8444e-02,\n",
      "         3.9210e-03, -3.3652e-02, -7.3943e-03,  7.9893e-03,  3.9206e-02,\n",
      "         3.7044e-02,  4.7699e-02, -4.5447e-02, -3.5762e-02,  4.5820e-02,\n",
      "        -4.4242e-02,  1.7856e-02,  5.9333e-03,  3.2571e-02,  1.1847e-01,\n",
      "         5.5450e-02,  3.9421e-02,  1.8565e-02, -1.0450e-02,  2.6470e-03,\n",
      "        -2.2663e-02,  7.9599e-02,  8.5458e-03,  7.5856e-02, -1.0787e-02,\n",
      "         1.5526e-01,  8.4370e-02,  2.1325e-02,  3.7506e-02, -3.0262e-02,\n",
      "         6.5601e-02,  4.6913e-02, -2.6032e-03,  5.6119e-02, -3.1941e-02,\n",
      "         3.7456e-02,  4.1997e-03, -2.2422e-02,  4.1679e-02,  1.7250e-02,\n",
      "         3.4809e-03, -1.9777e-02, -6.7071e-02, -5.6367e-02,  4.6742e-02,\n",
      "         3.3934e-02, -3.3244e-03, -1.8634e-03, -3.0922e-02, -6.0237e-02,\n",
      "         5.2534e-04, -3.0215e-03,  3.1754e-02,  1.0277e-01, -1.4452e-03,\n",
      "         3.0849e-02,  2.7902e-02,  5.1419e-02, -1.9777e-02, -6.0762e-02,\n",
      "         1.0828e-01,  7.5379e-02, -6.6977e-03,  3.7003e-02, -2.4300e-02,\n",
      "         7.6230e-03,  2.3223e-02,  1.7524e-02, -5.3481e-02,  1.0778e-01,\n",
      "         5.5552e-02,  2.5539e-02,  2.3091e-02,  5.8898e-02,  2.2049e-02,\n",
      "         3.2623e-02,  5.8066e-02,  3.7725e-02,  2.7082e-03,  9.1510e-02,\n",
      "         4.8364e-02,  2.5851e-02,  5.0182e-02,  4.7937e-02,  4.5597e-02,\n",
      "         1.8574e-02, -3.3128e-02,  1.6021e-02,  1.8097e-02,  1.7472e-02,\n",
      "         6.0375e-02,  3.8171e-02,  8.2182e-02, -4.3193e-03,  4.6906e-02,\n",
      "         3.1633e-02, -4.2151e-02,  1.0298e-01, -2.9976e-04, -3.9288e-02,\n",
      "        -2.1534e-03,  1.7219e-02, -3.1001e-02, -7.3016e-02,  1.0867e-02,\n",
      "        -2.2472e-02, -6.8946e-02,  3.6942e-02, -3.2147e-02, -5.7080e-03,\n",
      "         3.3292e-02,  4.7618e-03,  4.2494e-02,  3.8110e-02,  3.0593e-02,\n",
      "        -2.7699e-02,  5.9018e-02,  2.6771e-02, -7.7475e-03, -8.0766e-03,\n",
      "         1.0552e-01,  3.8302e-02,  7.0903e-03, -8.4021e-02, -9.0611e-03,\n",
      "         8.9726e-02,  5.8559e-02, -2.3162e-02,  4.0500e-02, -3.4117e-02,\n",
      "        -2.6084e-02, -5.6836e-02, -1.8584e-02,  3.1332e-02,  3.6927e-02,\n",
      "        -2.0269e-03, -2.0322e-02, -7.5867e-04, -4.3515e-02,  2.0338e-02,\n",
      "        -6.0051e-02,  3.7344e-02,  4.5521e-03, -8.0622e-03,  8.1891e-02,\n",
      "        -1.9595e-02,  7.6851e-02,  5.7947e-02, -7.9975e-02, -1.4319e-02,\n",
      "         5.7971e-02,  1.1097e-02, -8.0454e-04,  2.2627e-02,  1.5486e-02,\n",
      "         2.3125e-02, -4.4649e-04,  2.2928e-02,  1.4676e-02,  3.6921e-02,\n",
      "         1.2237e-02,  3.3981e-02, -2.7515e-03, -1.9846e-02,  4.3970e-02,\n",
      "        -3.3843e-02, -4.8433e-02, -2.4778e-02, -1.7885e-02,  7.1037e-02,\n",
      "        -1.4551e-02, -3.1797e-02, -2.1153e-02,  7.8190e-03, -1.8455e-02,\n",
      "         1.1818e-03,  5.2481e-02, -2.8626e-02,  5.3633e-02, -1.6114e-02,\n",
      "         4.9092e-02,  3.8349e-02,  1.1186e-02,  8.2933e-02,  3.6620e-02,\n",
      "         2.8855e-02, -2.4173e-02, -2.0903e-02,  6.2868e-02, -4.4602e-03,\n",
      "        -1.4821e-02, -2.3536e-02,  4.3552e-02,  1.7909e-03,  2.9454e-02,\n",
      "        -5.5435e-02,  9.8082e-03, -4.3728e-02, -4.5217e-02,  3.5778e-02,\n",
      "         3.5459e-02, -1.6226e-02, -4.0777e-02,  8.0172e-02,  3.0003e-04,\n",
      "        -6.9734e-02,  9.2327e-02,  8.7332e-02, -1.5882e-02, -5.0773e-03,\n",
      "        -1.8168e-03, -5.3149e-02, -1.0497e-03,  5.5068e-03,  4.4889e-02,\n",
      "        -8.4217e-02,  2.8463e-02, -5.2897e-02,  2.5948e-02,  5.5314e-02,\n",
      "        -2.9992e-02,  2.5026e-02,  2.7934e-02,  3.3074e-02,  5.3545e-03,\n",
      "         2.7005e-03,  2.9700e-02,  1.2299e-02,  4.3918e-02,  5.8009e-03,\n",
      "         5.7190e-02,  2.5365e-02, -6.2975e-02, -6.1349e-02, -5.0910e-02,\n",
      "        -1.2906e-02,  2.8360e-02,  6.5863e-02,  3.5261e-02, -7.9101e-03,\n",
      "         7.3779e-02, -7.5745e-03, -1.9186e-02, -6.1666e-02,  3.5893e-02],\n",
      "       requires_grad=True)]\n",
      "layer 2:\n",
      "[Parameter containing:\n",
      "tensor([[-7.7061e-02, -2.3309e-01,  3.8446e-02,  ..., -1.6165e-01,\n",
      "          2.7753e-04,  6.3468e-02],\n",
      "        [-1.5375e-02, -1.2730e-02, -1.1653e-01,  ...,  2.8658e-02,\n",
      "          7.5794e-03,  1.3849e-01],\n",
      "        [-1.4670e-01,  1.0659e-01,  2.9586e-02,  ...,  1.8770e-02,\n",
      "          1.1155e-02,  1.0701e-01],\n",
      "        ...,\n",
      "        [-9.7859e-02,  5.1389e-02, -4.3696e-02,  ...,  5.4164e-02,\n",
      "         -8.3698e-03,  2.4726e-02],\n",
      "        [ 6.8566e-02,  6.6355e-02,  4.7580e-02,  ...,  1.2310e-03,\n",
      "          6.5812e-02, -2.7194e-01],\n",
      "        [-3.9793e-02, -1.6211e-01,  3.0175e-02,  ..., -7.7299e-02,\n",
      "         -3.7987e-03, -3.6984e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0479, -0.0236,  0.0244, -0.0221,  0.0430,  0.0371,  0.0069, -0.0041,\n",
      "         0.0372, -0.0036], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print('Average Active Neurons =', np.count_nonzero(output_relu)/output_relu.shape[0])\n",
    "\n",
    "print('layer 1:')\n",
    "w_fc1 = list(model.fc1.parameters())\n",
    "print(w_fc1)\n",
    "\n",
    "print('layer 2:')\n",
    "w_fc2 = list(model.fc2.parameters())\n",
    "print(w_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.1 %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#future work\n",
    "def relu_at(A, threshold):\n",
    "    return torch.max(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "def relu_min_at(A, threshold):\n",
    "    return torch.min(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "class ThresholdingNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ThresholdingNet2, self).__init__()\n",
    "        self.maxlu = ReLU_my()\n",
    "        self.minlu = ReLU_min()\n",
    "        self.fc1 = nn.Linear(input_size*2, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        out1 = self.maxlu(out)\n",
    "        out2 = self.minlu(out)\n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out  \n",
    "    \n",
    "# model = ThresholdingNet(input_size, hidden_size, num_classes).to(device)\n",
    "model = ThresholdingNet2(input_size, hidden_size, num_classes).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
