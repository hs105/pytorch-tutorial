{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because the last layer takes input from relu and the y signal is positive; so the last layer's weight should be positively initialized.\n",
    "#layer-wise weight init: study intialization effects on relu diff idea. Can you find a more accurate model by different initialization?\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "num_workers=0\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=True,\n",
    "                                   download=False, transform=transform)\n",
    "test_data = datasets.MNIST(root='/Users/dongcui/github/visualising-cnns/data', train=False,\n",
    "                                  download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2399\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1367\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1416\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1378\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0749\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1253\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1318\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0969\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0902\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0247\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0405\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0861\n",
      "Epoch [3/5], Step [100/600], Loss: 0.1014\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0689\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0465\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0512\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0274\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0829\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0556\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0598\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0607\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0107\n",
      "Epoch [4/5], Step [500/600], Loss: 0.1072\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0207\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0273\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0155\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0094\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0229\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0255\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0577\n",
      "elapsed:  91.74539542198181\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07258784153188268\n",
      "torch.Size([500, 100])\n",
      "np.count_nonzero(output_relu)= 19763\n",
      "sparsity 0.60474\n",
      "Accuracy of the network on the 10000 test images: 97.72 %\n"
     ]
    }
   ],
   "source": [
    "def relu_diff(input1, input2):\n",
    "    '''this is sparse: two level-relu'''\n",
    "    return torch.max(input1 - input2, torch.zeros_like(input1))\n",
    "    \n",
    "class ReLU_my(nn.Module):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    References:\n",
    "        -  Related paper:\n",
    "        https://arxiv.org/pdf/1606.08415.pdf\n",
    "    Examples:\n",
    "        >>> m = silu()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__() # init the base class\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return relu_diff(input1, input2)\n",
    "\n",
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "#         m.weight.data.normal_(0.0, 1)#93% accuracy for relu; \n",
    "#         m.weight.data.normal_(-1, 1)# 11% accuracy for relu; 93.62 for this idea. \n",
    "        m.weight.data.normal_(1, 1)#92.87\n",
    "    \n",
    "def weight_sparse(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "#         init.sparse_(m.weight.data, 0.3, 0.01)\n",
    "#         init.sparse_(m.weight.data, 0.7, 0.01)\n",
    "        init.sparse_(m.weight.data, 0.7, 0.1)\n",
    "#         init.sparse_(m.weight.data, 0.7, 1.0)#worse\n",
    "\n",
    "def weight_layer_wise(m):\n",
    "    #98.12% fc3 using default\n",
    "#     init.sparse_(m.fc1.weight.data, 0.7, 0.1)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "\n",
    "    #98.14% fc3 using default\n",
    "#     init.sparse_(m.fc1.weight.data, 0.3, 0.1)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "    \n",
    "    #98.28. 98.0 98.03: there is randomness\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.1)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "    \n",
    "    #98.04\n",
    "#     init.sparse_(m.fc1.weight.data, 0.01, 0.1)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "    \n",
    "    #98.18\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.1)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.5, 0.1)\n",
    "    \n",
    "    #97.88\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.1)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.9, 0.1)\n",
    "\n",
    "    #97.79\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.1)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "#     init.sparse_(m.fc3.weight.data, 0.7, 0.1)\n",
    "\n",
    "    #97.99\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.1)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "#     init.sparse_(m.fc3.weight.data, 0.1, 0.1)\n",
    "    \n",
    "    #97.99\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.1)\n",
    "\n",
    "    #97.69\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "    \n",
    "    #98.15, 97.92\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.1)\n",
    "#     init.uniform_(m.fc1.bias.data, 0, 0.01)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "#     init.uniform_(m.fc2.bias.data, 0, 0.01)\n",
    "    \n",
    "    #98.07\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.1)\n",
    "#     init.uniform_(m.fc1.bias.data, -0.01, 0.01)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.1)\n",
    "#     init.uniform_(m.fc2.bias.data, -0.01, 0.01)\n",
    "    \n",
    "    #97.53\n",
    "#     init.sparse_(m.fc1.weight.data, 0.1, 0.5)\n",
    "#     init.uniform_(m.fc1.bias.data, -0.01, 0.01)\n",
    "#     init.sparse_(m.fc2.weight.data, 0.7, 0.5)\n",
    "#     init.uniform_(m.fc2.bias.data, -0.01, 0.01)\n",
    "    \n",
    "    #97.72\n",
    "    init.sparse_(m.fc1.weight.data, 0.1, 0.01)\n",
    "    init.uniform_(m.fc1.bias.data, -0.01, 0.01)\n",
    "    init.sparse_(m.fc2.weight.data, 0.7, 0.01)\n",
    "    init.uniform_(m.fc2.bias.data, -0.01, 0.01)\n",
    "    \n",
    "# print(np.random.binomial(1, 0.5, 5))\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = ReLU_my()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        out1 = self.fc1(out)\n",
    "        out2 = self.fc2(out)\n",
    "        \n",
    "        out_relu = self.relu(out1, out2)\n",
    "        out = self.fc3(out_relu)\n",
    "        return out, out_relu  \n",
    "#optionally add a sigmoid to the blocking; not sparse\n",
    "#     def forward(self, x):\n",
    "#         out = x\n",
    "        \n",
    "#         out1 = self.fc1(out)\n",
    "#         out2 = self.fc2(out)\n",
    "#         out2 = self.sigmoid(out2)\n",
    "        \n",
    "#         out_relu = self.relu(out1, out2)\n",
    "#         out = self.fc3(out_relu)\n",
    "#         return out, out_relu  \n",
    "\n",
    "#now I can define my model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "#model.apply(weight_sparse)\n",
    "weight_layer_wise(model)\n",
    "\n",
    "\n",
    "#visualzing graphs\n",
    "# writer=SummaryWriter('runs/experiment_1')\n",
    "# dataiter=iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(images.shape)\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# #writer.add_image('images', grid, 0)\n",
    "\n",
    "# #images = images.reshape(-1, 28*28).to(device)\n",
    "# dummy_input = torch.zeros(1, 28*28),\n",
    "# writer.add_graph(model, dummy_input)\n",
    "# writer.close()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, _  = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "\n",
    "print('elapsed: ', time.time()-start)\n",
    "plt.plot(losses, '-b+')\n",
    "plt.show()\n",
    "print(np.mean(losses))\n",
    "\n",
    "#check dead neurons\n",
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.reshape(-1, 28*28).to(device)\n",
    "# print(images.shape)\n",
    "A1 = images[:300]\n",
    "# print(A1.shape)\n",
    "output, output_relu = model(A1)\n",
    "\n",
    "output_relu = output_relu.T.detach()\n",
    "print(output_relu.shape)\n",
    "# plt.plot(output_relu.numpy(), '-b+')\n",
    "# plt.show()\n",
    "print('np.count_nonzero(output_relu)=', np.count_nonzero(output_relu))\n",
    "print('sparsity', 1- np.count_nonzero(output_relu)/ (output_relu.shape[0] * output_relu.shape[1]))\n",
    "\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "labels_wrong = []\n",
    "pred_wrong = []\n",
    "img_wrong = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, labels in test_loader:\n",
    "#         print(img.shape)\n",
    "        images = img.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        wrong_preds = (predicted != labels).numpy()\n",
    "        wrong_index = []\n",
    "        for (i, wrong) in enumerate(wrong_preds):\n",
    "            if wrong:\n",
    "                wrong_index.append(i) \n",
    "        if len(wrong_index) > 0:\n",
    "            img_reshaped = img[wrong_index].numpy()[:,0,:,:]\n",
    "            for img_w in range(img_reshaped.shape[0]):\n",
    "                img_wrong.append(img_reshaped[img_w])\n",
    "            labels_wrong  += (labels[wrong_index].numpy().tolist())\n",
    "            pred_wrong += (predicted[wrong_index].numpy().tolist())\n",
    "#     print(img_wrong)\n",
    "#     print('img_wrong.shape', img_wrong[0].shape)\n",
    "#     print('lables_wrong =', labels_wrong)\n",
    "#     print('predictions wrong are:', pred_wrong)\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "#show wrong images:\n",
    "# print(len(img_wrong), ', ', len(labels_wrong), ', ', len(pred_wrong))\n",
    "# for i in range(len(img_wrong)):\n",
    "#     plt.imshow(img_wrong[i])\n",
    "#     print('labels_wrong[i]:', labels_wrong[i])\n",
    "#     print('pred_wrong[i]', pred_wrong[i])\n",
    "#     plt.pause(1)\n",
    "\n",
    "# Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.5779,  0.0640,  0.1430, -0.1617, -0.5140,  0.3530,  0.5737, -0.1477,\n",
      "          0.1958, -0.1691],\n",
      "        [ 0.4743,  0.2682, -0.5371, -0.1988,  0.2150, -0.6793, -0.1516,  0.6180,\n",
      "         -0.3148, -0.7621],\n",
      "        [ 0.2593, -0.1268, -0.0784,  0.0650,  0.3511, -0.3761,  0.4965, -0.7066,\n",
      "          0.4375, -0.4512],\n",
      "        [-0.4706,  0.6136, -0.5341, -0.2328,  0.5161, -0.2980, -0.2179, -0.1023,\n",
      "          0.1481,  0.2383],\n",
      "        [ 0.0301, -0.7920,  0.7271, -0.2208,  0.5299,  0.3283, -0.6619, -0.1630,\n",
      "         -0.1853, -0.2730],\n",
      "        [-0.7178, -0.2460, -0.3829, -0.0773,  0.0664,  0.3904, -0.1010,  0.4212,\n",
      "          0.1781,  0.1411],\n",
      "        [ 0.1937, -0.3704,  0.1585, -0.1834, -0.6606,  0.0736, -0.4391,  0.3063,\n",
      "          0.6534, -0.7792],\n",
      "        [ 0.3262,  0.5748,  0.1930, -0.1342, -0.3776,  0.3556,  0.1013, -0.6247,\n",
      "         -0.7301,  0.2556],\n",
      "        [ 0.2724, -0.5699, -0.5487,  0.0173,  0.0711,  0.0028, -0.0344,  0.0607,\n",
      "          0.2700,  0.4230],\n",
      "        [ 0.1526, -0.0439,  0.4754, -0.0905, -0.4418, -0.4576, -0.2354,  0.1002,\n",
      "         -0.1119,  0.6380]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3967,  0.0543,  0.1003,  0.0194,  0.2582,  0.5695,  0.0319,  0.3185,\n",
      "        -0.4473, -0.1333], requires_grad=True)]\n",
      "layer 1:\n",
      "[Parameter containing:\n",
      "tensor([[ 0.0190,  0.0344, -0.0007,  ...,  0.0145, -0.0254,  0.0243],\n",
      "        [-0.0303,  0.0309,  0.0042,  ..., -0.0326, -0.0123, -0.0125],\n",
      "        [-0.0008, -0.0013,  0.0232,  ...,  0.0080,  0.0222, -0.0120],\n",
      "        ...,\n",
      "        [-0.0047, -0.0164,  0.0308,  ..., -0.0316, -0.0282,  0.0220],\n",
      "        [-0.0104, -0.0291,  0.0317,  ...,  0.0341,  0.0170, -0.0170],\n",
      "        [ 0.0081,  0.0353,  0.0004,  ..., -0.0056, -0.0110, -0.0028]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0456,  0.3276,  0.2901,  0.0216,  0.0949,  0.2920,  0.0664,  0.2952,\n",
      "        -0.2474, -0.2152], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print('layer 1:')\n",
    "w_fc1 = list(model.fc1.parameters())\n",
    "print(w_fc1)\n",
    "\n",
    "print('layer 2:')\n",
    "w_fc2 = list(model.fc2.parameters())\n",
    "print(w_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.12 %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#future work\n",
    "def relu_at(A, threshold):\n",
    "    return torch.max(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "def relu_min_at(A, threshold):\n",
    "    return torch.min(A, torch.ones_like(A) * threshold)\n",
    "\n",
    "class ThresholdingNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ThresholdingNet2, self).__init__()\n",
    "        self.maxlu = ReLU_my()\n",
    "        self.minlu = ReLU_min()\n",
    "        self.fc1 = nn.Linear(input_size*2, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        out1 = self.maxlu(out)\n",
    "        out2 = self.minlu(out)\n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out  \n",
    "    \n",
    "# model = ThresholdingNet(input_size, hidden_size, num_classes).to(device)\n",
    "model = ThresholdingNet2(input_size, hidden_size, num_classes).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
